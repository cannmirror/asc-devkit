/**
 * Copyright (c) 2025 Huawei Technologies Co., Ltd.
 * This program is free software, you can redistribute it and/or modify it under the terms and conditions of
 * CANN Open Software License Agreement Version 2.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#if !defined(ASCENDC_C_API_INCLUDE_COMPILER_INTERNAL_HEADERS)
#warning "impl/c_api/instr_impl/npu_arch_2201/cube_datamove_impl.h is an internal header file and must not be used directly. Functions or variables defined in this file maybe removed in the future. Please use "#include "c_api/asc_simd.h"" and use public functions or variables defined in interface headers files."
#define ASCENDC_C_API_INCLUDE_COMPILER_INTERNAL_HEADERS
#define UNDEF_ASCENDC_C_API_INCLUDE_COMPILER_INTERNAL_HEADERS_ASCENDC
#endif

#ifndef IMPL_C_API_C_API_INSTR_IMPL_CUBE_DATAMOVE_C_API_IMPL_CUBE_DATAMOVE_C_API_IMPL_H
#define IMPL_C_API_C_API_INSTR_IMPL_CUBE_DATAMOVE_C_API_IMPL_CUBE_DATAMOVE_C_API_IMPL_H

#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l12l0b_sparse_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l12bt.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_set_l13d_rpt_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_set_l13d_padding_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_set_l0c_copy_params_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_set_l0c_copy_prequant_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l12l0b_trans_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_set_l13d_size_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_load_image_to_cbuf_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_fill_l0a_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_fill_l0b_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_fill_l1_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l12fb_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_gm2l1_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_gm2l1_nd2nz_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l0c2l1_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l12l0a_2d_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l12l0a_3d_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l12l0b_2d_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l12l0b_3d_impl.h"
#include "instr_impl/npu_arch_2201/cube_datamove_impl/asc_copy_l0c2gm_impl.h"

__aicore__ inline void asc_copy_l12l0b_sparse(__cb__ int8_t* dst, __cbuf__ int8_t* src, __cbuf__ int8_t* index,
                                              uint16_t start_index, uint8_t repeat)
{
    asc_copy_l12l0b_sparse_impl(dst, src, index, start_index, repeat);
}

__aicore__ inline void asc_copy_l12l0b_sparse_sync(__cb__ int8_t* dst, __cbuf__ int8_t* src, __cbuf__ int8_t* index,
                                                   uint16_t start_index, uint8_t repeat)
{
    asc_copy_l12l0b_sparse_sync_impl(dst, src, index, start_index, repeat);
}

__aicore__ inline void asc_set_l13d_rpt(asc_load3d_v2_config& config)
{
    asc_set_l13d_rpt_impl(config);
}

// ==========asc_copy_l12l0b, 2D, int4b_t/int8_t/uint8_t/half/bfloat16_t/int32_t/uint32_t/float==========
__aicore__ inline void asc_copy_l12l0b(__cb__ int4b_t* dst, __cbuf__ int4b_t* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0b_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ int4b_t* dst, __cbuf__ int4b_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ int8_t* dst, __cbuf__ int8_t* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0b_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ int8_t* dst, __cbuf__ int8_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ uint8_t* dst, __cbuf__ uint8_t* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0b_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ uint8_t* dst, __cbuf__ uint8_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ half* dst, __cbuf__ half* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0b_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ half* dst, __cbuf__ half* src, uint16_t start_index, uint8_t repeat,
                                            uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                            uint8_t addr_mode)
{
    asc_copy_l12l0b_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t start_index,
                                       uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                       bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ int32_t* dst, __cbuf__ int32_t* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0b_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ int32_t* dst, __cbuf__ int32_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t start_index,
                                       uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                       bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ float* dst, __cbuf__ float* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0b_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ float* dst, __cbuf__ float* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0b_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

// ==========asc_copy_l12l0b, 3D, half/bfloat16_t/int32_t/uint32_t/float==========
__aicore__ inline void asc_copy_l12l0b(__cb__ half* dst, __cbuf__ half* src, uint16_t k_extension, uint16_t m_extension,
                                       uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w, uint8_t stride_h,
                                       uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0b_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ half* dst, __cbuf__ half* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0b_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0b_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0b_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ int32_t* dst, __cbuf__ int32_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0b_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ int32_t* dst, __cbuf__ int32_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0b_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0b_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0b_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b(__cb__ float* dst, __cbuf__ float* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0b_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0b_sync(__cb__ float* dst, __cbuf__ float* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0b_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

// ==========asc_copy_l12l0a, 2D, int4b_t*/int8_t/uint8_t/half/bfloat16_t/int32_t/uint32_t/float==========
__aicore__ inline void asc_copy_l12l0a(__ca__ int4b_t* dst, __cbuf__ int4b_t* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0a_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ int4b_t* dst, __cbuf__ int4b_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ int8_t* dst, __cbuf__ int8_t* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0a_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ int8_t* dst, __cbuf__ int8_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ uint8_t* dst, __cbuf__ uint8_t* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0a_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ uint8_t* dst, __cbuf__ uint8_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ half* dst, __cbuf__ half* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0a_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ half* dst, __cbuf__ half* src, uint16_t start_index, uint8_t repeat,
                                            uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                            uint8_t addr_mode)
{
    asc_copy_l12l0a_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t start_index,
                                       uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                       bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ int32_t* dst, __cbuf__ int32_t* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0a_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ int32_t* dst, __cbuf__ int32_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t start_index,
                                       uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                       bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ float* dst, __cbuf__ float* src, uint16_t start_index, uint8_t repeat,
                                       uint16_t src_stride, uint16_t dst_gap, uint8_t sid, bool transpose,
                                       uint8_t addr_mode)
{
    asc_copy_l12l0a_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ float* dst, __cbuf__ float* src, uint16_t start_index,
                                            uint8_t repeat, uint16_t src_stride, uint16_t dst_gap, uint8_t sid,
                                            bool transpose, uint8_t addr_mode)
{
    asc_copy_l12l0a_sync_impl(dst, src, start_index, repeat, src_stride, dst_gap, sid, transpose, addr_mode);
}

// ==========asc_copy_l12l0a, 3D, int4b_t*/int8_t/uint8_t/half/bfloat16_t/int32_t/uint32_t/float==========
__aicore__ inline void asc_copy_l12l0a(__ca__ int4b_t* dst, __cbuf__ int4b_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0a_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ int4b_t* dst, __cbuf__ int4b_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0a_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ int8_t* dst, __cbuf__ int8_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0a_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ int8_t* dst, __cbuf__ int8_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0a_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ uint8_t* dst, __cbuf__ uint8_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0a_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ uint8_t* dst, __cbuf__ uint8_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0a_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ half* dst, __cbuf__ half* src, uint16_t k_extension, uint16_t m_extension,
                                       uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w, uint8_t stride_h,
                                       uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0a_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ half* dst, __cbuf__ half* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0a_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0a_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0a_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ int32_t* dst, __cbuf__ int32_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0a_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ int32_t* dst, __cbuf__ int32_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0a_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0a_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0a_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a(__ca__ float* dst, __cbuf__ float* src, uint16_t k_extension,
                                       uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt, uint8_t stride_w,
                                       uint8_t stride_h, uint8_t filter_w, uint8_t filter_h, uint8_t dilation_filter_w,
                                       uint8_t dilation_filter_h, bool filter_size_w, bool filter_size_h,
                                       bool transpose, bool f_matrix_ctrl, uint16_t channel_size)
{
    asc_copy_l12l0a_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                         filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                         f_matrix_ctrl, channel_size);
}

__aicore__ inline void asc_copy_l12l0a_sync(__ca__ float* dst, __cbuf__ float* src, uint16_t k_extension,
                                            uint16_t m_extension, uint16_t k_start_pt, uint16_t m_start_pt,
                                            uint8_t stride_w, uint8_t stride_h, uint8_t filter_w, uint8_t filter_h,
                                            uint8_t dilation_filter_w, uint8_t dilation_filter_h, bool filter_size_w,
                                            bool filter_size_h, bool transpose, bool f_matrix_ctrl,
                                            uint16_t channel_size)
{
    asc_copy_l12l0a_sync_impl(dst, src, k_extension, m_extension, k_start_pt, m_start_pt, stride_w, stride_h, filter_w,
                              filter_h, dilation_filter_w, dilation_filter_h, filter_size_w, filter_size_h, transpose,
                              f_matrix_ctrl, channel_size);
}

// ==========asc_l0c_copy_params()==========
__aicore__ inline void asc_set_l0c_copy_params(uint16_t nd_num, uint16_t src_nd_stride, uint16_t dst_nd_stride)
{
    set_l0c_copy_params_impl(nd_num, src_nd_stride, dst_nd_stride);
}

__aicore__ inline void asc_set_l13d_size(uint64_t value)
{
    asc_set_l13d_size_impl(value);
}

// ==========asc_load_image_to_cbuf(half/int8_t)==========
__aicore__ inline void asc_load_image_to_cbuf(__cbuf__ half* dst, uint16_t hor_size, uint16_t ver_size,
                                              uint16_t hor_start_pos, uint16_t ver_start_pos, uint16_t src_hor_size,
                                              uint8_t top_pad_size, uint8_t bot_pad_size, uint16_t left_pad_size,
                                              uint16_t right_pad_size)
{
    asc_load_image_to_cbuf_impl(dst, hor_size, ver_size, hor_start_pos, ver_start_pos, src_hor_size, top_pad_size,
                                bot_pad_size, left_pad_size, right_pad_size);
}

__aicore__ inline void asc_load_image_to_cbuf_sync(__cbuf__ half* dst, uint16_t hor_size, uint16_t ver_size,
                                                   uint16_t hor_start_pos, uint16_t ver_start_pos,
                                                   uint16_t src_hor_size, uint8_t top_pad_size, uint8_t bot_pad_size,
                                                   uint16_t left_pad_size, uint16_t right_pad_size)
{
    asc_load_image_to_cbuf_sync_impl(dst, hor_size, ver_size, hor_start_pos, ver_start_pos, src_hor_size, top_pad_size,
                                     bot_pad_size, left_pad_size, right_pad_size);
}

__aicore__ inline void asc_load_image_to_cbuf(__cbuf__ int8_t* dst, uint16_t hor_size, uint16_t ver_size,
                                              uint16_t hor_start_pos, uint16_t ver_start_pos, uint16_t src_hor_size,
                                              uint8_t top_pad_size, uint8_t bot_pad_size, uint16_t left_pad_size,
                                              uint16_t right_pad_size)
{
    asc_load_image_to_cbuf_impl(dst, hor_size, ver_size, hor_start_pos, ver_start_pos, src_hor_size, top_pad_size,
                                bot_pad_size, left_pad_size, right_pad_size);
}

__aicore__ inline void asc_load_image_to_cbuf_sync(__cbuf__ int8_t* dst, uint16_t hor_size, uint16_t ver_size,
                                                   uint16_t hor_start_pos, uint16_t ver_start_pos,
                                                   uint16_t src_hor_size, uint8_t top_pad_size, uint8_t bot_pad_size,
                                                   uint16_t left_pad_size, uint16_t right_pad_size)
{
    asc_load_image_to_cbuf_sync_impl(dst, hor_size, ver_size, hor_start_pos, ver_start_pos, src_hor_size, top_pad_size,
                                     bot_pad_size, left_pad_size, right_pad_size);
}

// ==========asc_fill_l0a(half/float/int16_t/int32_t/uint16_t/uint32_t/bfloat16_t)==========
__aicore__ inline void asc_fill_l0a(__ca__ half* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ half* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ half* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ half* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ float* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ float* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ float* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ float* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ int16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ int16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ int16_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ int16_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ int32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ int32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ int32_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ int32_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ uint16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ uint16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ uint16_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ uint16_t* dst, uint32_t value,
                                               const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ uint32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ uint32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ uint32_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ uint32_t* dst, uint32_t value,
                                               const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a(__ca__ bfloat16_t* dst, bfloat16_t value, const asc_fill_value_config& config)
{
    asc_fill_l0a_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0a_sync(__ca__ bfloat16_t* dst, bfloat16_t value,
                                               const asc_fill_value_config& config)
{
    asc_fill_l0a_sync_impl(dst, value, config);
}

// ==========asc_fill_l0b(half/float/int16_t/int32_t/uint16_t/uint32_t/bfloat16_t)==========
__aicore__ inline void asc_fill_l0b(__cb__ half* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ half* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ half* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ half* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ float* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ float* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ float* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ float* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ int16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ int16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ int16_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ int16_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ int32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ int32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ int32_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ int32_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ uint16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ uint16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ uint16_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ uint16_t* dst, uint32_t value,
                                               const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ uint32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ uint32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ uint32_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ uint32_t* dst, uint32_t value,
                                               const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b(__cb__ bfloat16_t* dst, bfloat16_t value, const asc_fill_value_config& config)
{
    asc_fill_l0b_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l0b_sync(__cb__ bfloat16_t* dst, bfloat16_t value,
                                               const asc_fill_value_config& config)
{
    asc_fill_l0b_sync_impl(dst, value, config);
}

// ==========asc_fill_l1(half/float/int16_t/int32_t/uint16_t/uint32_t/bfloat16_t)==========
__aicore__ inline void asc_fill_l1(__cbuf__ half* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ half* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ half* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ half* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ float* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ float* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ float* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ float* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ int16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ int16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ int16_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ int16_t* dst, uint32_t value,
                                              const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ int32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ int32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ int32_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ int32_t* dst, uint32_t value,
                                              const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ uint16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ uint16_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ uint16_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ uint16_t* dst, uint32_t value,
                                              const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ uint32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ uint32_t* dst, half value, const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ uint32_t* dst, uint32_t value, const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ uint32_t* dst, uint32_t value,
                                              const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1(__cbuf__ bfloat16_t* dst, bfloat16_t value,
                                         const asc_fill_value_config& config)
{
    asc_fill_l1_impl(dst, value, config);
}

__aicore__ inline void asc_fill_l1_sync(__cbuf__ bfloat16_t* dst, bfloat16_t value,
                                              const asc_fill_value_config& config)
{
    asc_fill_l1_sync_impl(dst, value, config);
}
// ==========asc_copy_l12l0b_trans=========
__aicore__ inline void asc_copy_l12l0b_trans(__cb__ half* dst, __cbuf__ half* src, uint16_t index_id, uint8_t repeat,
                                             uint16_t src_stride, uint16_t dst_stride, bool addrmode,
                                             uint16_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans(__cb__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t index_id,
                                             uint8_t repeat, uint16_t src_stride, uint16_t dst_stride, bool addrmode,
                                             uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans_sync(__cb__ bfloat16_t* dst, __cbuf__ bfloat16_t* src, uint16_t index_id,
                                                  uint8_t repeat, uint16_t src_stride, uint16_t dst_stride,
                                                  bool addrmode, uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_sync_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans(__cb__ float* dst, __cbuf__ float* src, uint16_t index_id, uint8_t repeat,
                                             uint16_t src_stride, uint16_t dst_stride, bool addrmode,
                                             uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans(__cb__ int32_t* dst, __cbuf__ int32_t* src, uint16_t index_id,
                                             uint8_t repeat, uint16_t src_stride, uint16_t dst_stride, bool addrmode,
                                             uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans(__cb__ int8_t* dst, __cbuf__ int8_t* src, uint16_t index_id,
                                             uint8_t repeat, uint16_t src_stride, uint16_t dst_stride, bool addrmode,
                                             uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans(__cb__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t index_id,
                                             uint8_t repeat, uint16_t src_stride, uint16_t dst_stride, bool addrmode,
                                             uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans(__cb__ uint8_t* dst, __cbuf__ uint8_t* src, uint16_t index_id,
                                             uint8_t repeat, uint16_t src_stride, uint16_t dst_stride, bool addrmode,
                                             uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans_sync(__cb__ half* dst, __cbuf__ half* src, uint16_t index_id,
                                                  uint8_t repeat, uint16_t src_stride, uint16_t dst_stride,
                                                  bool addrmode, uint16_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_sync_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans_sync(__cb__ float* dst, __cbuf__ float* src, uint16_t index_id,
                                                  uint8_t repeat, uint16_t src_stride, uint16_t dst_stride,
                                                  bool addrmode, uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_sync_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans_sync(__cb__ int32_t* dst, __cbuf__ int32_t* src, uint16_t index_id,
                                                  uint8_t repeat, uint16_t src_stride, uint16_t dst_stride,
                                                  bool addrmode, uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_sync_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans_sync(__cb__ int8_t* dst, __cbuf__ int8_t* src, uint16_t index_id,
                                                  uint8_t repeat, uint16_t src_stride, uint16_t dst_stride,
                                                  bool addrmode, uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_sync_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans_sync(__cb__ uint32_t* dst, __cbuf__ uint32_t* src, uint16_t index_id,
                                                  uint8_t repeat, uint16_t src_stride, uint16_t dst_stride,
                                                  bool addrmode, uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_sync_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

__aicore__ inline void asc_copy_l12l0b_trans_sync(__cb__ uint8_t* dst, __cbuf__ uint8_t* src, uint16_t index_id,
                                                  uint8_t repeat, uint16_t src_stride, uint16_t dst_stride,
                                                  bool addrmode, uint64_t dst_frac_stride)
{
    asc_copy_l12l0b_trans_sync_impl(dst, src, index_id, repeat, src_stride, dst_stride, addrmode, dst_frac_stride);
}

// ==========asc_copy_gm2l1==========
__aicore__ inline void asc_copy_gm2l1(__cbuf__ void* dst, __gm__ void* src, uint16_t n_burst,
                                      uint16_t burst_len, uint16_t src_stride, uint16_t dst_stride, pad_t pad_mode)
{
    asc_copy_gm2l1_impl(dst, src, n_burst, burst_len, src_stride, dst_stride, pad_mode);
}

__aicore__ inline void asc_copy_gm2l1(__cbuf__ void* dst, __gm__ void* src, uint32_t size)
{
    asc_copy_gm2l1_impl(dst, src, size);
}

__aicore__ inline void asc_copy_gm2l1_sync(__cbuf__ void* dst, __gm__ void* src, uint32_t size)
{
    asc_copy_gm2l1_sync_impl(dst, src, size);
}

// ==========asc_copy_gm2l1_nd2nz b8(int8_t/uint8_t)==========
__aicore__ inline void asc_copy_gm2l1_nd2nz(__cbuf__ int8_t* dst, __gm__ int8_t* src, uint16_t nd_num,
                                            uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                            uint16_t src_d_value, uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                            uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                              dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz_sync(__cbuf__ int8_t* dst, __gm__ int8_t* src, uint16_t nd_num,
                                                 uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                                 uint16_t src_d_value, uint16_t dst_nz_c0_stride,
                                                 uint16_t dst_nz_n_stride, uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_sync_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                                   dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz(__cbuf__ uint8_t* dst, __gm__ uint8_t* src, uint16_t nd_num,
                                            uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                            uint16_t src_d_value, uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                            uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                              dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz_sync(__cbuf__ uint8_t* dst, __gm__ uint8_t* src,
                                                 uint16_t nd_num, uint16_t n_value, uint16_t d_value,
                                                 uint16_t src_nd_matrix_stride, uint16_t src_d_value,
                                                 uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                                 uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_sync_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                                   dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

// ==========asc_copy_gm2l1_nd2nz b16(bfloat16_t/half/int16_t)==========
__aicore__ inline void asc_copy_gm2l1_nd2nz(__cbuf__ bfloat16_t* dst, __gm__ bfloat16_t* src,
                                            uint16_t nd_num, uint16_t n_value, uint16_t d_value,
                                            uint16_t src_nd_matrix_stride, uint16_t src_d_value,
                                            uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                            uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                              dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz_sync(__cbuf__ bfloat16_t* dst, __gm__ bfloat16_t* src,
                                                 uint16_t nd_num, uint16_t n_value, uint16_t d_value,
                                                 uint16_t src_nd_matrix_stride, uint16_t src_d_value,
                                                 uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                                 uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_sync_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                                   dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz(__cbuf__ half* dst, __gm__ half* src, uint16_t nd_num,
                                            uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                            uint16_t src_d_value, uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                            uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                              dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz_sync(__cbuf__ half* dst, __gm__ half* src, uint16_t nd_num,
                                                 uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                                 uint16_t src_d_value, uint16_t dst_nz_c0_stride,
                                                 uint16_t dst_nz_n_stride, uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_sync_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                                   dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz(__cbuf__ int16_t* dst, __gm__ int16_t* src, uint16_t nd_num,
                                            uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                            uint16_t src_d_value, uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                            uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                              dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz_sync(__cbuf__ int16_t* dst, __gm__ int16_t* src,
                                                 uint16_t nd_num, uint16_t n_value, uint16_t d_value,
                                                 uint16_t src_nd_matrix_stride, uint16_t src_d_value,
                                                 uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                                 uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_sync_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                                   dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

// ==========asc_copy_gm2l1_nd2nz b32s(float/int32_t/uint32_t)==========
__aicore__ inline void asc_copy_gm2l1_nd2nz(__cbuf__ float* dst, __gm__ float* src, uint16_t nd_num,
                                            uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                            uint16_t src_d_value, uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                            uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                              dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz_sync(__cbuf__ float* dst, __gm__ float* src, uint16_t nd_num,
                                                 uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                                 uint16_t src_d_value, uint16_t dst_nz_c0_stride,
                                                 uint16_t dst_nz_n_stride, uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_sync_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                                   dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz(__cbuf__ int32_t* dst, __gm__ int32_t* src, uint16_t nd_num,
                                            uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                            uint16_t src_d_value, uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                            uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                              dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz_sync(__cbuf__ int32_t* dst, __gm__ int32_t* src,
                                                 uint16_t nd_num, uint16_t n_value, uint16_t d_value,
                                                 uint16_t src_nd_matrix_stride, uint16_t src_d_value,
                                                 uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                                 uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_sync_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                                   dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz(__cbuf__ uint32_t* dst, __gm__ uint32_t* src, uint16_t nd_num,
                                            uint16_t n_value, uint16_t d_value, uint16_t src_nd_matrix_stride,
                                            uint16_t src_d_value, uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                            uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                              dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

__aicore__ inline void asc_copy_gm2l1_nd2nz_sync(__cbuf__ uint32_t* dst, __gm__ uint32_t* src,
                                                 uint16_t nd_num, uint16_t n_value, uint16_t d_value,
                                                 uint16_t src_nd_matrix_stride, uint16_t src_d_value,
                                                 uint16_t dst_nz_c0_stride, uint16_t dst_nz_n_stride,
                                                 uint16_t dst_nz_matrix_stride)
{
    asc_copy_gm2l1_nd2nz_sync_impl(dst, src, nd_num, n_value, d_value, src_nd_matrix_stride, src_d_value,
                                   dst_nz_c0_stride, dst_nz_n_stride, dst_nz_matrix_stride);
}

//=============asc_copy_l12bt===============
__aicore__ inline void asc_copy_l12bt(uint64_t dst, __cbuf__ void* src, uint16_t conv_control, uint16_t n_burst,
                                      uint16_t len_burst, uint16_t source_gap, uint16_t dst_gap)
{
    asc_copy_l12bt_impl(dst, src, conv_control, n_burst, len_burst, source_gap, dst_gap);
}

__aicore__ inline void asc_copy_l12bt(uint64_t dst, __cbuf__ void* src, uint32_t size)
{
    asc_copy_l12bt_impl(dst, src, size);
}

__aicore__ inline void asc_copy_l12bt_sync(uint64_t dst, __cbuf__ void* src, uint32_t size)
{
    asc_copy_l12bt_sync_impl(dst, src, size);
}

//=============asc_copy_l12fb===============
__aicore__ inline void asc_copy_l12fb(__fbuf__ void* dst, __cbuf__ void* src, uint16_t burst_num, uint16_t burst_len,
                                      uint16_t src_gap_size, uint16_t dst_gap_size)
{
    asc_copy_l12fb_impl(dst, src, burst_num, burst_len, src_gap_size, dst_gap_size);
}

__aicore__ inline void asc_copy_l12fb(__fbuf__ void* dst, __cbuf__ void* src, uint32_t size)
{
    asc_copy_l12fb_impl(dst, src, size);
}

__aicore__ inline void asc_copy_l12fb_sync(__fbuf__ void* dst, __cbuf__ void* src, uint32_t size)
{
    asc_copy_l12fb_sync_impl(dst, src, size);
}

__aicore__ inline void asc_set_l0c_copy_prequant(uint64_t config)
{
    asc_set_l0c_copy_prequant_impl(config);
}

__aicore__ inline void asc_set_l13d_padding(uint64_t config)
{
    asc_set_l13d_padding_impl(config);
}

__aicore__ inline void asc_set_l13d_padding(half config)
{
    asc_set_l13d_padding_impl(config);
}

__aicore__ inline void asc_set_l13d_padding(int16_t config)
{
    asc_set_l13d_padding_impl(config);
}

__aicore__ inline void asc_set_l13d_padding(uint16_t config)
{
    asc_set_l13d_padding_impl(config);
}

// ==========asc_copy_l0c2gm==========
__aicore__ inline void asc_copy_l0c2gm(__gm__ half* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                             quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ half* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                                uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                                uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm(__gm__ bfloat16_t* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ bfloat16_t* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                                uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                                uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm(__gm__ int8_t* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ int8_t* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                                uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                                uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm(__gm__ uint8_t* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                             quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ uint8_t* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                                uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                                uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                            quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm(__gm__ float* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ float* dst, __cc__ float* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                            quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm(__gm__ half* dst, __cc__ int32_t* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ half* dst, __cc__ int32_t* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                              quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm(__gm__ int16_t* dst, __cc__ int32_t* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ int16_t* dst, __cc__ int32_t* src, uint16_t n_size, uint16_t m_size, 
                                                uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                                uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm(__gm__ int8_t* dst, __cc__ int32_t* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                             quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ int8_t* dst, __cc__ int32_t* src, uint16_t n_size, uint16_t m_size, 
                                                uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                                uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm(__gm__ int32_t* dst, __cc__ int32_t* src, uint16_t n_size, uint16_t m_size, 
                                            uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                            uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                         quant_pre, relu_pre, channel_split, nz2nd_en);
}

__aicore__ inline void asc_copy_l0c2gm_sync(__gm__ int32_t* dst, __cc__ int32_t* src, uint16_t n_size, uint16_t m_size, 
                                                uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t unit_flag_mode, 
                                                uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nz2nd_en)
{
    asc_copy_l0c2gm_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, unit_flag_mode,
                            quant_pre, relu_pre, channel_split, nz2nd_en);
}

// ==========asc_copy_l0c2l1==========
__aicore__ inline void asc_copy_l0c2l1(__cbuf__ half* dst, __cc__ float* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode,
                            quant_pre, relu_pre, channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1_sync(__cbuf__ half* dst, __cc__ float* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode, quant_pre, relu_pre,
                        channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1(__cbuf__ bfloat16_t* dst, __cc__ float* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode,
                            quant_pre, relu_pre, channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1_sync(__cbuf__ bfloat16_t* dst, __cc__ float* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode, quant_pre, relu_pre,
                        channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1(__cbuf__ int8_t* dst, __cc__ float* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode,
                            quant_pre, relu_pre, channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1_sync(__cbuf__ int8_t* dst, __cc__ float* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode, quant_pre, relu_pre,
                        channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1(__cbuf__ half* dst, __cc__ int32_t* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode,
                            quant_pre, relu_pre, channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1_sync(__cbuf__ half* dst, __cc__ int32_t* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode, quant_pre, relu_pre,
                        channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1(__cbuf__ int16_t* dst, __cc__ int32_t* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode,
                            quant_pre, relu_pre, channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1_sync(__cbuf__ int16_t* dst, __cc__ int32_t* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode, quant_pre, relu_pre,
                        channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1(__cbuf__ int8_t* dst, __cc__ int32_t* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode,
                            quant_pre, relu_pre, channel_split, nd2nz_en);
}

__aicore__ inline void asc_copy_l0c2l1_sync(__cbuf__ int8_t* dst, __cc__ int32_t* src, uint16_t n_size,uint16_t m_size,
                                        uint32_t dst_stride_dst_d, uint16_t src_stride, uint8_t uint_flag_mode,
                                        uint64_t quant_pre, uint8_t relu_pre, bool channel_split, bool nd2nz_en)
{
    asc_copy_l0c2l1_sync_impl(dst, src, n_size, m_size, dst_stride_dst_d, src_stride, uint_flag_mode, quant_pre, relu_pre,
                        channel_split, nd2nz_en);
}

#endif

#if defined(UNDEF_ASCENDC_C_API_INCLUDE_COMPILER_INTERNAL_HEADERS_ASCENDC)
#undef ASCENDC_C_API_INCLUDE_COMPILER_INTERNAL_HEADERS
#undef UNDEF_ASCENDC_C_API_INCLUDE_COMPILER_INTERNAL_HEADERS_ASCENDC
#endif
