/**
* Copyright (c) 2025 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/


/* !
 * \file matmul.asc
 * \brief
 */
 
#include <sstream>
#include <iostream>
#include "acl/acl.h"
#include "kernel_operator.h"
#include "register/tilingdata_base.h"
#include "tiling/tiling_api.h"
#include "kernel_tiling/kernel_tiling.h"
#include "tiling/platform/platform_ascendc.h"
#include "data_utils.h"
#define ASCENDC_CUBE_ONLY
#include "lib/matmul_intf.h"


struct MatmulCaseParams
{
    int32_t usedCoreNum;
    int32_t m;
    int32_t n;
    int32_t k;
    bool isBias;
    bool isATrans;
    bool isBTrans;
};

TCubeTiling generateTiling(const MatmulCaseParams& testCaseParams)
{
    TCubeTiling tilingData;
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    matmul_tiling::MultiCoreMatmulTiling cubeTiling(*ascendcPlatform);
    
    uint32_t M = testCaseParams.m;
    uint32_t N = testCaseParams.n;
    uint32_t K = testCaseParams.k;
    uint32_t numBlocks = testCaseParams.usedCoreNum;
    bool isBias = testCaseParams.isBias;
    bool isAtrans = testCaseParams.isATrans;
    bool isBtrans = testCaseParams.isBTrans;

    cubeTiling.SetDim(numBlocks);
    cubeTiling.SetAType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::COLUMN_MAJOR,
        matmul_tiling::DataType::DT_FLOAT16, isAtrans);
    cubeTiling.SetBType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::COLUMN_MAJOR,
        matmul_tiling::DataType::DT_FLOAT16, isBtrans);
    cubeTiling.SetCType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::COLUMN_MAJOR,
        matmul_tiling::DataType::DT_FLOAT);
    cubeTiling.SetBiasType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND,
        matmul_tiling::DataType::DT_FLOAT);
    
    cubeTiling.SetOrgShape(M, N, K);
    cubeTiling.SetShape(M, N, K);
    cubeTiling.EnableBias(isBias);
    cubeTiling.SetBufferSpace(-1, -1, -1);
    
    if (cubeTiling.GetTiling(tilingData) == -1) {
        std::cout << "Generate tiling failed." << std::endl;
        return {};
    }
    
    return tilingData;
}

template <typename ATYPE, typename BType, typename CType, typename BiasType>
class MatmulKernel {
public:
    __aicore__ inline MatmulKernel(){};
    
    __aicore__ inline void init(GM_ADDR a, GM_ADDR b, GM_ADDR bias, GM_ADDR c, const TCubeTiling& tiling,
        bool isTransA, bool isTransB);
    
    __aicore__ inline void process();
    
    AscendC::Matmul<
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::COLUMN_MAJOR, ATYPE>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::COLUMN_MAJOR, BType>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::COLUMN_MAJOR, CType>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, BiasType>> matmulObj;

private:
    __aicore__ inline void calcOffset(int32_t blockIdx, int32_t& offsetA, int32_t& offsetB, 
                                     int32_t& offsetC, int32_t& offsetBias);

    AscendC::GlobalTensor<ATYPE> aGlobal;
    AscendC::GlobalTensor<BType> bGlobal;
    AscendC::GlobalTensor<CType> cGlobal;
    AscendC::GlobalTensor<BiasType> biasGlobal;
    TCubeTiling tiling;
    int32_t mCoreIndex;
    int32_t nCoreIndex;
    bool isTransA{false};
    bool isTransB{false};
};

__aicore__ inline void copyTiling(TCubeTiling* tiling, GM_ADDR tilingGm)
{
    uint32_t* ptr = reinterpret_cast<uint32_t*>(tiling);
    auto tiling32 = reinterpret_cast<__gm__ uint32_t*>(tilingGm);

    for (int i = 0; i < sizeof(TCubeTiling) / sizeof(uint32_t); i++, ptr++) {
        *ptr = *(tiling32 + i);
    }
    
    return;
}

template <typename AType, typename BType, typename CType, typename BiasType>
__aicore__ inline void MatmulKernel<AType, BType, CType, BiasType>::init(GM_ADDR a, GM_ADDR b, GM_ADDR bias,
    GM_ADDR c, const TCubeTiling& tiling, bool isTransA, bool isTransB)
{
    this->tiling = tiling;
    this->isTransA = isTransA;
    this->isTransB = isTransB;

    aGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ AType*>(a), tiling.M * tiling.Ka);
    bGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ BType*>(b), tiling.Kb * tiling.N);
    cGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ CType*>(c), tiling.M * tiling.N);
    biasGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ BiasType*>(bias), tiling.N);

    int32_t offsetA = 0;
    int32_t offsetB = 0;
    int32_t offsetC = 0;
    int32_t offsetBias = 0;
    
    calcOffset(AscendC::GetBlockIdx(), offsetA, offsetB, offsetC, offsetBias);
    
    aGlobal = aGlobal[offsetA];
    bGlobal = bGlobal[offsetB];
    cGlobal = cGlobal[offsetC];
    biasGlobal = biasGlobal[offsetBias];
    
    if (GetSysWorkSpacePtr() == nullptr) {
        return;
    }
}

template <typename AType, typename BType, typename CType, typename BiasType>
__aicore__ inline void MatmulKernel<AType, BType, CType, BiasType>::process()
{
    if (AscendC::GetBlockIdx() >= tiling.usedCoreNum) {
        return;
    }

    int tailM = tiling.M - mCoreIndex * tiling.singleCoreM;
    tailM = tailM < tiling.singleCoreM ? tailM : tiling.singleCoreM;
    
    int tailN = tiling.N - nCoreIndex * tiling.singleCoreN;
    tailN = tailN < tiling.singleCoreN ? tailN : tiling.singleCoreN;
    
    if (tailM < tiling.singleCoreM || tailN < tiling.singleCoreN) {
        matmulObj.SetTail(tailM, tailN);
    }

    matmulObj.SetTensorA(aGlobal, isTransA);
    matmulObj.SetTensorB(bGlobal, isTransB);
    
    if (tiling.isBias) {
        matmulObj.SetBias(biasGlobal);
    }

    matmulObj.IterateAll(cGlobal);
    matmulObj.End();
}

template <typename AType, typename BType, typename CType, typename BiasType>
__aicore__ inline void MatmulKernel<AType, BType, CType, BiasType>::calcOffset(
    int32_t blockIdx, int32_t& offsetA, int32_t& offsetB, int32_t& offsetC, int32_t& offsetBias)
{
    const TCubeTiling& tiling = this->tiling;
    auto mSingleBlocks = (tiling.M + tiling.singleCoreM - 1) / tiling.singleCoreM;
    mCoreIndex = blockIdx % mSingleBlocks;
    nCoreIndex = blockIdx / mSingleBlocks;

    if (isTransA == 0) {
        offsetA = mCoreIndex * tiling.singleCoreM;
    } else {
        offsetA = mCoreIndex * tiling.Ka * tiling.singleCoreM;
    }
    
    if (isTransB == 0) {
        offsetB = nCoreIndex * tiling.Kb * tiling.singleCoreN;
    } else {
        offsetB = nCoreIndex * tiling.singleCoreN;
    }

    offsetC = nCoreIndex * tiling.M * tiling.singleCoreN + mCoreIndex * tiling.singleCoreM;
    offsetBias = nCoreIndex * tiling.singleCoreN;
}

__cube__ __global__ void matmulColumnMajorCustom(
    GM_ADDR a, GM_ADDR b, GM_ADDR bias, GM_ADDR c, GM_ADDR workspace, GM_ADDR tilingGm)
{
    KERNEL_TASK_TYPE_DEFAULT(KERNEL_TYPE_AIC_ONLY);
    
    TCubeTiling tiling;
    copyTiling(&tiling, tilingGm);
    
    MatmulKernel<half, half, float, float> matmulKernel;
    AscendC::TPipe pipe;
    
    REGIST_MATMUL_OBJ(&pipe, GetSysWorkSpacePtr(), matmulKernel.matmulObj, &tiling);
    
    matmulKernel.init(a, b, bias, c, tiling, false, false);
    matmulKernel.process();
}

void matmulColumnMajorCustomDo(uint32_t numBlocks, void* stream,
    GM_ADDR a, GM_ADDR b, GM_ADDR bias, GM_ADDR c, GM_ADDR workspace, GM_ADDR tilingGm)
{
    matmulColumnMajorCustom<<<numBlocks, nullptr, stream>>>(a, b, bias, c, workspace, tilingGm);
}

constexpr bool IS_BIAS = true;
constexpr bool IS_A_TRANS = false;
constexpr bool IS_B_TRANS = false;

struct MatrixFileSize
{
    size_t x1FileSize;
    size_t x2FileSize;
    size_t yFileSize;
    size_t biasFileSize;
};

static size_t getSysWorkSpaceSize()
{
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    
    if (ascendcPlatform == nullptr) {
        return 0;
    }
    
    return static_cast<size_t>(ascendcPlatform->GetLibApiWorkSpaceSize());
}

void matmulOp(uint8_t* x1, uint8_t* x2, uint8_t* y, uint8_t* bias, int64_t m, int64_t n, int64_t k,
    void* stream = nullptr)
{
    uint8_t *workspaceDevice;
    size_t workspaceSize = getSysWorkSpaceSize();
    
    aclrtMalloc((void **)&workspaceDevice, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);

    uint8_t* tilingHost;
    uint8_t* tilingDevice;
    size_t tilingFileSize = sizeof(TCubeTiling);
    
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    MatmulCaseParams testCaseParams{static_cast<int32_t>(ascendcPlatform->GetCoreNumAic()),
        static_cast<int32_t>(m), static_cast<int32_t>(n), static_cast<int32_t>(k), IS_BIAS, IS_A_TRANS, IS_B_TRANS};
    
    const auto tilingData = generateTiling(testCaseParams);
    
    aclrtMallocHost((void **)(&tilingHost), tilingFileSize);
    aclrtMalloc((void **)&tilingDevice, tilingFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    
    aclrtMemcpy(tilingHost, tilingFileSize, &tilingData, tilingFileSize, ACL_MEMCPY_HOST_TO_HOST);
    aclrtMemcpy(tilingDevice, tilingFileSize, tilingHost, tilingFileSize, ACL_MEMCPY_HOST_TO_DEVICE);
    
    matmulColumnMajorCustomDo(tilingData.usedCoreNum, stream, x1, x2, bias, y, workspaceDevice, tilingDevice);
    
    aclrtFreeHost(tilingHost);
    aclrtFree(workspaceDevice);
    aclrtFree(tilingDevice);
}

void testAclInit(aclrtContext &context, aclrtStream &stream, int64_t &deviceId)
{
    aclInit(nullptr);
    aclrtSetDevice(deviceId);
    aclrtCreateContext(&context, deviceId);
    aclrtCreateStream(&stream);
}

void testAclDeInit(aclrtContext &context, aclrtStream &stream, int64_t &deviceId)
{
    aclrtDestroyStream(stream);
    aclrtDestroyContext(context);
    aclrtResetDevice(deviceId);
    aclFinalize();
}

void testMatmul(int64_t m, int64_t n, int64_t k, const MatrixFileSize& matrixFileSize)
{
    size_t x1FileSize = matrixFileSize.x1FileSize;
    size_t x2FileSize = matrixFileSize.x2FileSize;
    size_t yFileSize = matrixFileSize.yFileSize;
    size_t biasFileSize = matrixFileSize.biasFileSize;

    aclrtContext context;
    aclrtStream stream = nullptr;
    int64_t deviceId = 0;
    
    testAclInit(context, stream, deviceId);

    uint8_t *x1Host;
    uint8_t *x1Device;
    aclrtMallocHost((void **)(&x1Host), x1FileSize);
    aclrtMalloc((void **)&x1Device, x1FileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/x1_gm.bin", x1FileSize, x1Host, x1FileSize);
    aclrtMemcpy(x1Device, x1FileSize, x1Host, x1FileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t *x2Host;
    uint8_t *x2Device;
    aclrtMallocHost((void **)(&x2Host), x2FileSize);
    aclrtMalloc((void **)&x2Device, x2FileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/x2_gm.bin", x2FileSize, x2Host, x2FileSize);
    aclrtMemcpy(x2Device, x2FileSize, x2Host, x2FileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t *biasHost = nullptr;
    uint8_t *biasDevice = nullptr;
    
    if (IS_BIAS) {
        aclrtMallocHost((void **)(&biasHost), biasFileSize);
        aclrtMalloc((void **)&biasDevice, biasFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
        ReadFile("./input/bias_gm.bin", biasFileSize, biasHost, biasFileSize);
        aclrtMemcpy(biasDevice, biasFileSize, biasHost, biasFileSize, ACL_MEMCPY_HOST_TO_DEVICE);
    }
    
    uint8_t *yHost = nullptr;
    uint8_t *yDevice = nullptr;
    aclrtMallocHost((void **)(&yHost), yFileSize);
    aclrtMalloc((void **)&yDevice, yFileSize, ACL_MEM_MALLOC_HUGE_FIRST);

    matmulOp(x1Device, x2Device, yDevice, biasDevice, m, n, k, stream);
    aclrtSynchronizeStream(stream);

    aclrtMemcpy(yHost, yFileSize, yDevice, yFileSize, ACL_MEMCPY_DEVICE_TO_HOST);
    WriteFile("./output/output.bin", yHost, yFileSize);

    if (IS_BIAS) {
        aclrtFree(biasDevice);
        aclrtFreeHost(biasHost);
    }
    
    aclrtFree(x1Device);
    aclrtFreeHost(x1Host);
    aclrtFree(x2Device);
    aclrtFreeHost(x2Host);
    aclrtFree(yDevice);
    aclrtFreeHost(yHost);
    
    testAclDeInit(context, stream, deviceId);
}

int32_t main(int32_t argc, const char *args[])
{
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    int64_t M = 428;
    int64_t N = 479;
    int64_t K = 528;
    
    MatrixFileSize matrixFileSize;
    matrixFileSize.x1FileSize = static_cast<size_t>(M * K) * sizeof(uint16_t);
    matrixFileSize.x2FileSize = static_cast<size_t>(K * N) * sizeof(uint16_t);
    matrixFileSize.yFileSize = static_cast<size_t>(M * N) * sizeof(float);
    matrixFileSize.biasFileSize = static_cast<size_t>(1 * N) * sizeof(float);
    
    testMatmul(M, N, K, matrixFileSize);
    
    return 0;
}