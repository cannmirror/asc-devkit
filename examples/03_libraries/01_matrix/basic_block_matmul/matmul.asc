/**
* Copyright (c) 2025 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/

#include <cassert>
#include <fstream>
#include <iostream>
#include <map>
#include <string>
#include "register/tilingdata_base.h"
#include "tiling/tiling_api.h"
#include "kernel_operator.h"
#include "lib/matmul_intf.h"
#include "tiling/platform/platform_ascendc.h"
#include "data_utils.h"
#include "kernel_tiling/kernel_tiling.h"
#include "acl/acl.h"

constexpr MatmulConfig MM_CFG = GetBasicConfig(128, 256, 64); // baseM, baseN, baseK
constexpr int32_t USED_CORE_NUM = 4;
constexpr int32_t M = 512;
constexpr int32_t N = 1024;
constexpr int32_t K = 512;
constexpr int32_t baseM = 128;
constexpr int32_t baseN = 256;
constexpr int32_t baseK = 64;

namespace optiling {
BEGIN_TILING_DATA_DEF(MatmulCustomTilingData)
  TILING_DATA_FIELD_DEF_STRUCT(TCubeTiling, cubeTilingData);
END_TILING_DATA_DEF;

REGISTER_TILING_DATA_CLASS(BasicBlockMatmulCustom, MatmulCustomTilingData)
}

bool ComputeTiling(optiling::TCubeTiling& tiling, matmul_tiling::MultiCoreMatmulTiling* cubeTiling,
                   int32_t M, int32_t N, int32_t K,int32_t baseM, int32_t baseN, int32_t baseK,
                   int32_t blockDim, bool isBias)
{
    cubeTiling->SetDim(blockDim);
    cubeTiling->SetAType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT16, true); // A is transposed
    cubeTiling->SetBType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT16);
    cubeTiling->SetCType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT);
    cubeTiling->SetBiasType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT);
    cubeTiling->SetShape(M, N, K);
    cubeTiling->SetOrgShape(M, N, K);
    cubeTiling->SetFixSplit(baseM, baseN, baseK);
    cubeTiling->EnableBias(isBias);
    cubeTiling->SetBufferSpace(-1, -1, -1);
    if (cubeTiling->GetTiling(tiling) == -1) {
        return false;
    }
    return true;
}

struct BasicBlockMatrixOffset {
    int32_t offsetA = 0;
    int32_t offsetB = 0;
    int32_t offsetC = 0;
    int32_t offsetBias = 0;
};

template <typename aType, typename bType, typename cType, typename biasType>
class BasicBlockMatmulKernel {
    public:
        __aicore__ inline BasicBlockMatmulKernel(){};
        __aicore__ inline void Init(GM_ADDR a, GM_ADDR b, GM_ADDR bias, GM_ADDR c, GM_ADDR workspace, const TCubeTiling& tiling);
        template <bool hasBias = false>
        __aicore__ inline void Process(AscendC::TPipe* pipe);
        AscendC::Matmul<AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, aType, true>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, bType>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, cType>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, biasType>, MM_CFG> matmulObj;

    private:
        __aicore__ inline void CalcOffset(int32_t blockIdx, const TCubeTiling& tiling, BasicBlockMatrixOffset& matrixOffset,
                                          bool isAtrans, bool isBtrans);

        AscendC::GlobalTensor<aType> aGlobal;
        AscendC::GlobalTensor<bType> bGlobal;
        AscendC::GlobalTensor<cType> cGlobal;
        AscendC::GlobalTensor<biasType> biasGlobal;
        TCubeTiling tiling;
};

template <typename aType, typename bType, typename cType, typename biasType>
__aicore__ inline void BasicBlockMatmulKernel<aType, bType, cType, biasType>::Init(GM_ADDR a, GM_ADDR b, GM_ADDR bias, GM_ADDR c,
                                                                         GM_ADDR workspace, const TCubeTiling& tiling)
{
    this->tiling = tiling;
    aGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ aType*>(a), tiling.M * tiling.Ka);
    bGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ bType*>(b), tiling.Kb * tiling.N);
    cGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ cType*>(c), tiling.M * tiling.N);
    biasGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ biasType*>(bias), tiling.N);

    struct BasicBlockMatrixOffset matrixOffset;
    bool isAtrans = true;
    bool isBtrans = false;
    CalcOffset(AscendC::GetBlockIdx(), tiling, matrixOffset, isAtrans, isBtrans);
    aGlobal = aGlobal[matrixOffset.offsetA];
    bGlobal = bGlobal[matrixOffset.offsetB];
    cGlobal = cGlobal[matrixOffset.offsetC];
    biasGlobal = biasGlobal[matrixOffset.offsetBias];
    if(GetSysWorkSpacePtr() == nullptr){
        return;
    }
}

template <typename aType, typename bType, typename cType, typename biasType>
template <bool hasBias>
__aicore__ inline void BasicBlockMatmulKernel<aType, bType, cType, biasType>::Process(AscendC::TPipe* pipe)
{
    matmulObj.SetTensorA(aGlobal, true); // A matrix transpose
    matmulObj.SetTensorB(bGlobal);
    if constexpr (hasBias) {
        matmulObj.SetBias(biasGlobal);
    }
    matmulObj.IterateAll(cGlobal);
    matmulObj.End();
}

__aicore__ inline uint32_t Ceiling(uint32_t a, uint32_t b)
{
    if (b == 0) {
        return 0;
    }
    return (a + b - 1) / b;
}

template <typename aType, typename bType, typename cType, typename biasType>
__aicore__ inline void BasicBlockMatmulKernel<aType, bType, cType, biasType>::CalcOffset(int32_t blockIdx, const TCubeTiling& tiling,
    BasicBlockMatrixOffset& matrixOffset, bool isAtrans, bool isBtrans)
{
    auto mSingleBlocks = Ceiling(tiling.M, tiling.singleCoreM);
    auto mCoreIndx = blockIdx % mSingleBlocks;
    auto nCoreIndx = blockIdx / mSingleBlocks;

    matrixOffset.offsetA = mCoreIndx * tiling.Ka * tiling.singleCoreM;
    if (isAtrans) {
        matrixOffset.offsetA = mCoreIndx * tiling.singleCoreM;
    }
    matrixOffset.offsetB = nCoreIndx * tiling.singleCoreN;
    if (isBtrans) {
        matrixOffset.offsetB = nCoreIndx * tiling.Kb * tiling.singleCoreN;
    }
    matrixOffset.offsetC = mCoreIndx * tiling.N * tiling.singleCoreM + nCoreIndx * tiling.singleCoreN;
    matrixOffset.offsetBias = nCoreIndx * tiling.singleCoreN;
}



uint8_t *GetTilingBuf(optiling::TCubeTiling *tilingData)
{
    if (tilingData == nullptr) {
        return nullptr;
    }
    uint32_t tilingSize = tilingData->GetDataSize();
    if (tilingSize <= 0) {
        return nullptr;
    }
    uint8_t *buf = (uint8_t *)malloc(tilingSize);
    if (buf == nullptr) {
        return nullptr;
    }
    tilingData->SaveToBuffer(buf, tilingSize);
    return buf;
}

uint8_t *GenerateTiling(platform_ascendc::PlatformAscendC* ascendcPlatform)
{
    optiling::TCubeTiling tilingData;
    matmul_tiling::MultiCoreMatmulTiling cubeTiling(*ascendcPlatform);
    bool res = ComputeTiling(tilingData, &cubeTiling, M, N, K,
                baseM, baseN, baseK, USED_CORE_NUM, false);
    if (!res) {
        std::cout << "gen tiling failed" << std::endl;
    }
    return GetTilingBuf(&tilingData);
}

__aicore__ inline void CopyTiling(TCubeTiling* tiling, GM_ADDR tilingGM)
{
    uint32_t* ptr = reinterpret_cast<uint32_t*>(tiling);
    auto tilingGmAddr = reinterpret_cast<__gm__ uint32_t*>(tilingGM);

    for (int i = 0; i < sizeof(TCubeTiling) / sizeof(uint32_t); i++, ptr++) {
      *ptr = *(tilingGmAddr + i);
    }
    return;
}

extern "C" __global__ __aicore__ void basic_block_matmul_custom(GM_ADDR a, GM_ADDR b, GM_ADDR c, GM_ADDR __kfc_workspace__ workspace, GM_ADDR tilingGm)
{
    // prepare tiling
    TCubeTiling tiling;
    CopyTiling(&tiling, tilingGm);
    // define matmul kernel
    BasicBlockMatmulKernel<half, half, float, float> matmulKernel;
    AscendC::TPipe pipe;
    REGIST_MATMUL_OBJ(&pipe, GetSysWorkSpacePtr(), matmulKernel.matmulObj, &tiling);
    // init matmul kernel
    matmulKernel.Init(a, b, nullptr, c, workspace, tiling);
    // matmul kernel process
    matmulKernel.Process<false>(&pipe);
}

int32_t main(int32_t argc, char *argv[])
{
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    size_t aFileSize = M * K * sizeof(uint16_t);   // uint16_t represent half
    size_t bFileSize = K * N * sizeof(uint16_t);  // uint16_t represent half
    size_t cFileSize = M * N * sizeof(float);
    size_t userWorkspaceSize = 0;
    size_t systemWorkspaceSize = static_cast<size_t>(ascendcPlatform->GetLibApiWorkSpaceSize());
    size_t workspaceSize = userWorkspaceSize + systemWorkspaceSize;
    size_t tilingFileSize = sizeof(TCubeTiling);
    int64_t wrongNum = -1;
    uint32_t blockDim = 2;
    auto tilingBuf = GenerateTiling(ascendcPlatform);
    if (tilingBuf == nullptr) {
        printf("generate tiling failed!\n");
    }
    aclInit(nullptr);
    aclrtContext context;
    int32_t deviceId = 0;
    aclrtSetDevice(deviceId);
    aclrtCreateContext(&context, deviceId);
    aclrtStream stream = nullptr;
    aclrtCreateStream(&stream);

    uint8_t *aHost;
    uint8_t *aDevice;
    aclrtMallocHost((void **)(&aHost), aFileSize);
    
        aclrtMalloc((void **)&aDevice, aFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("input/x1_gm.bin", aFileSize, aHost, aFileSize);
    aclrtMemcpy(aDevice, aFileSize, aHost, aFileSize,
                          ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t *bHost;
    uint8_t *bDevice;
    aclrtMallocHost((void **)(&bHost), bFileSize);
    
        aclrtMalloc((void **)&bDevice, bFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("input/x2_gm.bin", bFileSize, bHost, bFileSize);
    aclrtMemcpy(bDevice, bFileSize, bHost, bFileSize,
                          ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t *workspaceHost;
    uint8_t *workspaceDevice;
    aclrtMallocHost((void **)(&workspaceHost), workspaceSize);
    aclrtMalloc((void **)&workspaceDevice, workspaceSize,
                          ACL_MEM_MALLOC_HUGE_FIRST);

    uint8_t *tilingHost;
    uint8_t *tilingDevice;
    aclrtMallocHost((void **)(&tilingHost), tilingFileSize);
    aclrtMalloc((void **)&tilingDevice, tilingFileSize,
                          ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMemcpy(tilingHost, tilingFileSize, tilingBuf,
                          tilingFileSize, ACL_MEMCPY_HOST_TO_HOST);
    aclrtMemcpy(tilingDevice, tilingFileSize, tilingHost,
                          tilingFileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t *cHost;
    uint8_t *cDevice;
    aclrtMallocHost((void **)(&cHost), cFileSize);
    
        aclrtMalloc((void **)&cDevice, cFileSize, ACL_MEM_MALLOC_HUGE_FIRST);

    basic_block_matmul_custom<<<blockDim, nullptr, stream>>>(aDevice, bDevice, cDevice, workspaceDevice, tilingDevice);
    aclrtSynchronizeStream(stream);

    aclrtMemcpy(cHost, cFileSize, cDevice, cFileSize,
                          ACL_MEMCPY_DEVICE_TO_HOST);
    WriteFile("output/output.bin", cHost, cFileSize);

    aclrtFree(cDevice);
    aclrtFreeHost(cHost);

    aclrtFree(aDevice);
    aclrtFreeHost(aHost);

    aclrtFree(bDevice);
    aclrtFreeHost(bHost);

    aclrtFree(tilingDevice);
    aclrtFreeHost(tilingHost);

    aclrtFree(workspaceDevice);
    aclrtFreeHost(workspaceHost);

    aclrtDestroyStream(stream);
    aclrtDestroyContext(context);
    aclrtResetDevice(deviceId);
    aclFinalize();

    free(tilingBuf);
    return 0;
}
