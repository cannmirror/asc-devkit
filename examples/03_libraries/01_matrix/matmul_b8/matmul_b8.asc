/**
* Copyright (c) 2025 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/

/*!
 * \file matmul_b8.asc
 * \brief
 */
#include <iostream>
#include <sstream>
#include "register/tilingdata_base.h"
#include "tiling/tiling_api.h"
#include "kernel_operator.h"
#define ASCENDC_CUBE_ONLY
#include "lib/matmul_intf.h"
#include "acl/acl.h"
#include "tiling/platform/platform_ascendc.h"
#include "kernel_tiling/kernel_tiling.h"
#include "data_utils.h"

struct MatmulCaseParams
{
    int32_t usedCoreNum;
    int32_t m;
    int32_t n;
    int32_t k;
    bool isBias;
    bool isATrans;
    bool isBTrans;
};

constexpr bool IS_A_TRANS = false;
constexpr bool IS_B_TRANS = false;
constexpr bool IS_BIAS = true;

TCubeTiling generateTiling(const MatmulCaseParams& testCaseParams)
{
    TCubeTiling tilingData;
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    matmul_tiling::MultiCoreMatmulTiling tiling(*ascendcPlatform);
    
    int32_t M = testCaseParams.m;
    int32_t N = testCaseParams.n;
    int32_t K = testCaseParams.k;
    int32_t numBlocks = testCaseParams.usedCoreNum;
    bool isBias = testCaseParams.isBias;
    bool isAtrans = testCaseParams.isATrans;
    bool isBtrans = testCaseParams.isBTrans;

    tiling.SetDim(numBlocks);

    matmul_tiling::DataType aType = matmul_tiling::DataType::DT_HIFLOAT8;
    matmul_tiling::DataType bType = matmul_tiling::DataType::DT_HIFLOAT8;

#if DT_MODE == 1
    aType = matmul_tiling::DataType::DT_FLOAT8_E4M3FN;
    bType = matmul_tiling::DataType::DT_FLOAT8_E4M3FN;
#elif DT_MODE == 2
    aType = matmul_tiling::DataType::DT_FLOAT8_E5M2;
    bType = matmul_tiling::DataType::DT_FLOAT8_E5M2;
#elif DT_MODE == 3
    aType = matmul_tiling::DataType::DT_FLOAT8_E4M3FN;
    bType = matmul_tiling::DataType::DT_FLOAT8_E5M2;
#elif DT_MODE == 4
    aType = matmul_tiling::DataType::DT_FLOAT8_E5M2;
    bType = matmul_tiling::DataType::DT_FLOAT8_E4M3FN;
#endif

    tiling.SetAType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, aType, isAtrans);
    tiling.SetBType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, bType, isBtrans);
    tiling.SetCType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT);
    tiling.SetBiasType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT);
    
    tiling.SetOrgShape(M, N, K);
    tiling.SetShape(M, N, K);
    tiling.EnableBias(isBias);
    tiling.SetBufferSpace(-1, -1, -1);

    if (tiling.GetTiling(tilingData) == -1) {
        std::cout << "Generate tiling failed." << std::endl;
        return {};
    }

    return tilingData;
}

template <typename aType, typename bType, typename cType, typename biasType>
class MatmulB8Kernel
{
public:
    __aicore__ inline MatmulB8Kernel() {};
    
    __aicore__ inline void init(GM_ADDR a, GM_ADDR b, GM_ADDR bias, GM_ADDR c, GM_ADDR workspace,
        const TCubeTiling& tiling);
    
    __aicore__ inline void process(AscendC::TPipe* pipe);

    static constexpr MatmulConfig mmCfg = GetMDLConfig();

    AscendC::Matmul<AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, aType>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, bType>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, cType>,
        AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, biasType>, mmCfg> matmulObj;

private:
    __aicore__ inline void calcOffset(int32_t blockIdx, TCubeTiling& param, 
        int32_t& offsetA, int32_t& offsetB, int32_t& offsetC, int32_t& offsetBias);

    AscendC::GlobalTensor<aType> aGlobal;
    AscendC::GlobalTensor<bType> bGlobal;
    AscendC::GlobalTensor<cType> cGlobal;
    AscendC::GlobalTensor<biasType> biasGlobal;
    TCubeTiling tiling;
};

template <typename aType, typename bType, typename cType, typename biasType>
__aicore__ inline void MatmulB8Kernel<aType, bType, cType, biasType>::init(GM_ADDR a,
    GM_ADDR b, GM_ADDR bias, GM_ADDR c, GM_ADDR workspace, const TCubeTiling& tiling)
{
    this->tiling = tiling;
    aGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ aType*>(a), tiling.M * tiling.Ka);
    bGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ bType*>(b), tiling.Kb * tiling.N);
    cGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ cType*>(c), tiling.M * tiling.N);
    biasGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ biasType*>(bias), tiling.N);

    int32_t offsetA = 0;
    int32_t offsetB = 0;
    int32_t offsetC = 0;
    int32_t offsetBias = 0;
    
    calcOffset(AscendC::GetBlockIdx(), this->tiling, offsetA, offsetB, offsetC, offsetBias);
    
    aGlobal = aGlobal[offsetA];
    bGlobal = bGlobal[offsetB];
    cGlobal = cGlobal[offsetC];
    biasGlobal = biasGlobal[offsetBias];
    
    if (GetSysWorkSpacePtr() == nullptr) {
        return;
    }
}

template <typename aType, typename bType, typename cType, typename biasType>
__aicore__ inline void MatmulB8Kernel<aType, bType, cType, biasType>::process(AscendC::TPipe* pipe)
{
    REGIST_MATMUL_OBJ(pipe, GetSysWorkSpacePtr(), matmulObj, &(this->tiling));
    
    matmulObj.SetTensorA(aGlobal, false);
    matmulObj.SetTensorB(bGlobal, false);
    
    if (tiling.isBias) {
        matmulObj.SetBias(biasGlobal);
    }
    
    matmulObj.IterateAll(cGlobal);
    matmulObj.End();
}

template <typename aType, typename bType, typename cType, typename biasType>
__aicore__ inline void MatmulB8Kernel<aType, bType, cType, biasType>::calcOffset(
    int32_t blockIdx, TCubeTiling& param,
    int32_t& offsetA, int32_t& offsetB, int32_t& offsetC, int32_t& offsetBias)
{
    auto temp0 = AscendC::Ceil(param.M, param.singleCoreM);
    auto temp1 = AscendC::Ceil(param.N, param.singleCoreN);
    auto temp2 = AscendC::Ceil(param.Ka, param.singleCoreK);

    auto divideKCoreNum = param.usedCoreNum / temp2;
    auto mCoreIndex = (blockIdx % divideKCoreNum) % temp0;
    auto nCoreIndex = (blockIdx % divideKCoreNum) / temp0;
    auto subKIndex = blockIdx / divideKCoreNum;

    offsetA = mCoreIndex * param.Ka * param.singleCoreM + subKIndex * param.singleCoreK;
    offsetB = subKIndex * param.singleCoreK * param.N + nCoreIndex * param.singleCoreN;
    offsetC = mCoreIndex * param.N * param.singleCoreM + nCoreIndex * param.singleCoreN;
    offsetBias = nCoreIndex * param.singleCoreN;

    int32_t gmUseM = param.M - mCoreIndex * param.singleCoreM;
    param.singleCoreM = gmUseM < param.singleCoreM ? gmUseM : param.singleCoreM;

    int32_t gmUseN = param.N - nCoreIndex * param.singleCoreN;
    param.singleCoreN = gmUseN < param.singleCoreN ? gmUseN : param.singleCoreN;

    int32_t gmUseK = param.Ka - subKIndex * param.singleCoreK;
    param.singleCoreK = gmUseK < param.singleCoreK ? gmUseK : param.singleCoreK;
}

__aicore__ inline void copyTiling(TCubeTiling* tiling, GM_ADDR tilingGm)
{
    uint32_t* ptr = reinterpret_cast<uint32_t*>(tiling);
    auto tiling32 = reinterpret_cast<__gm__ uint32_t*>(tilingGm);

    for (int i = 0; i < sizeof(TCubeTiling) / sizeof(uint32_t); i++, ptr++) {
        *ptr = *(tiling32 + i);
    }
    
    return;
}

__cube__ __global__ void matmulB8Custom(GM_ADDR a, GM_ADDR b,
    GM_ADDR bias, GM_ADDR c, __kfc_workspace__ GM_ADDR workspace, GM_ADDR tilingGm)
{
    TCubeTiling tiling;
    copyTiling(&tiling, tilingGm);

#if DT_MODE == 1
    MatmulB8Kernel<fp8_e4m3fn_t, fp8_e4m3fn_t, float, float> matmulB8Kernel;
#elif DT_MODE == 2
    MatmulB8Kernel<fp8_e5m2_t, fp8_e5m2_t, float, float> matmulB8Kernel;
#elif DT_MODE == 3
    MatmulB8Kernel<fp8_e4m3fn_t, fp8_e5m2_t, float, float> matmulB8Kernel;
#elif DT_MODE == 4
    MatmulB8Kernel<fp8_e5m2_t, fp8_e4m3fn_t, float, float> matmulB8Kernel;
#else
    MatmulB8Kernel<hifloat8_t, hifloat8_t, float, float> matmulB8Kernel;
#endif
    
    AscendC::TPipe pipe;
    matmulB8Kernel.init(a, b, bias, c, workspace, tiling);
    matmulB8Kernel.process(&pipe);
}

void matmulB8CustomDo(uint32_t numBlocks, void* stream, GM_ADDR a, GM_ADDR b,
    GM_ADDR bias, GM_ADDR c, GM_ADDR workspace, GM_ADDR tilingGm)
{
    matmulB8Custom<<<numBlocks, nullptr, stream>>>(a, b, bias, c, workspace, tilingGm);
}

static size_t getSysWorkSpaceSize()
{
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    return static_cast<size_t>(ascendcPlatform->GetLibApiWorkSpaceSize());
}

void matmulOp(uint8_t* x1, uint8_t* x2, uint8_t* y, uint8_t* bias, int64_t m, int64_t n, int64_t k,
    void* stream = nullptr)
{
    uint8_t* workspaceDevice;
    size_t workspaceSize = getSysWorkSpaceSize();
    aclrtMalloc((void **)&workspaceDevice, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);

    uint8_t* tilingHost;
    uint8_t* tilingDevice;
    size_t tilingFileSize = sizeof(TCubeTiling);
    
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    MatmulCaseParams testCaseParams{static_cast<int32_t>(ascendcPlatform->GetCoreNumAic()),
        static_cast<int32_t>(m), static_cast<int32_t>(n), static_cast<int32_t>(k), IS_BIAS, IS_A_TRANS, IS_B_TRANS};
    
    const auto& tilingData = generateTiling(testCaseParams);
    
    aclrtMallocHost((void **)(&tilingHost), tilingFileSize);
    aclrtMalloc((void **)&tilingDevice, tilingFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    
    aclrtMemcpy(tilingHost, tilingFileSize, &tilingData, tilingFileSize, ACL_MEMCPY_HOST_TO_HOST);
    aclrtMemcpy(tilingDevice, tilingFileSize, tilingHost, tilingFileSize, ACL_MEMCPY_HOST_TO_DEVICE);
    
    matmulB8CustomDo(tilingData.usedCoreNum, stream, x1, x2, bias, y, workspaceDevice, tilingDevice);
    
    aclrtFreeHost(tilingHost);
    aclrtFree(workspaceDevice);
    aclrtFree(tilingDevice);
}

void testAclInit(aclrtContext& context, aclrtStream& stream, int64_t& deviceId)
{
    aclInit(nullptr);
    aclrtSetDevice(deviceId);
    aclrtCreateContext(&context, deviceId);
    aclrtCreateStream(&stream);
}

void testAclDeInit(aclrtContext& context, aclrtStream& stream, int64_t& deviceId)
{
    aclrtDestroyStream(stream);
    aclrtDestroyContext(context);
    aclrtResetDevice(deviceId);
    aclFinalize();
}

void testMatmul(int64_t m, int64_t n, int64_t k)
{
    size_t x1FileSize = static_cast<size_t>(m * k) * sizeof(uint8_t);
    size_t x2FileSize = static_cast<size_t>(k * n) * sizeof(uint8_t);
    size_t yFileSize = static_cast<size_t>(m * n) * sizeof(float);
    size_t biasFileSize = static_cast<size_t>(1 * n) * sizeof(float);

    aclrtContext context;
    aclrtStream stream = nullptr;
    int64_t deviceId = 0;
    
    testAclInit(context, stream, deviceId);

    uint8_t* x1Host;
    uint8_t* x1Device;
    aclrtMallocHost((void **)(&x1Host), x1FileSize);
    aclrtMalloc((void **)&x1Device, x1FileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/x1_gm.bin", x1FileSize, x1Host, x1FileSize);
    aclrtMemcpy(x1Device, x1FileSize, x1Host, x1FileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t* x2Host;
    uint8_t* x2Device;
    aclrtMallocHost((void **)(&x2Host), x2FileSize);
    aclrtMalloc((void **)&x2Device, x2FileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/x2_gm.bin", x2FileSize, x2Host, x2FileSize);
    aclrtMemcpy(x2Device, x2FileSize, x2Host, x2FileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t* biasHost = nullptr;
    uint8_t* biasDevice = nullptr;
    
    if (IS_BIAS) {
        aclrtMallocHost((void **)(&biasHost), biasFileSize);
        aclrtMalloc((void **)&biasDevice, biasFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
        ReadFile("./input/bias_gm.bin", biasFileSize, biasHost, biasFileSize);
        aclrtMemcpy(biasDevice, biasFileSize, biasHost, biasFileSize, ACL_MEMCPY_HOST_TO_DEVICE);
    }
    
    uint8_t* yHost = nullptr;
    uint8_t* yDevice = nullptr;
    aclrtMallocHost((void **)(&yHost), yFileSize);
    aclrtMalloc((void **)&yDevice, yFileSize, ACL_MEM_MALLOC_HUGE_FIRST);

    matmulOp(x1Device, x2Device, yDevice, biasDevice, m, n, k, stream);
    aclrtSynchronizeStream(stream);

    aclrtMemcpy(yHost, yFileSize, yDevice, yFileSize, ACL_MEMCPY_DEVICE_TO_HOST);
    WriteFile("./output/output.bin", yHost, yFileSize);

    if (IS_BIAS) {
        aclrtFree(biasDevice);
        aclrtFreeHost(biasHost);
    }
    
    aclrtFree(x1Device);
    aclrtFreeHost(x1Host);
    aclrtFree(x2Device);
    aclrtFreeHost(x2Host);
    aclrtFree(yDevice);
    aclrtFreeHost(yHost);
    
    testAclDeInit(context, stream, deviceId);
}

int32_t main(int32_t argc, const char* args[])
{
    constexpr uint32_t M = 428;
    constexpr uint32_t N = 479;
    constexpr uint32_t K = 158;
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();
    
    testMatmul(M, N, K);
    
    return 0;
}