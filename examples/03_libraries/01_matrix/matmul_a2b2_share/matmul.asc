/**
* Copyright (c) 2025 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/


/* !
 * \file matmul.asc
 * \brief
 */

#include "data_utils.h"
#include "kernel_tiling/kernel_tiling.h"
#include "tiling/platform/platform_ascendc.h"
#include "tiling/tiling_api.h"
#include "acl/acl.h"
#include "kernel_operator.h"
#define ASCENDC_CUBE_ONLY
#include "lib/matmul_intf.h"

constexpr uint32_t M = 7680;
constexpr uint32_t N = 480;
constexpr uint32_t K = 320;
constexpr bool IS_TRANS_A = false;
constexpr bool IS_TRANS_B = false;
constexpr bool IS_BIAS = true;

/**
 * @brief  Copy tiling data to TCubeTiling ptr from tiling gm addr.
 * @param  tiling: TCubeTiling ptr which needs to copy tiling data.
 * @param  tilingGM: tiling gm addr.
 * @retval None
 */
__aicore__ inline void CopyTiling(TCubeTiling* tiling, GM_ADDR tilingGM)
{
    uint32_t* ptr = reinterpret_cast<uint32_t*>(tiling);
    auto tiling32 = reinterpret_cast<__gm__ uint32_t*>(tilingGM);

    for (uint32_t i = 0; i < sizeof(TCubeTiling) / sizeof(uint32_t); i++, ptr++) { *ptr = *(tiling32 + i); }
    return;
}

__aicore__ inline constexpr MatmulConfig GetCustomCFG()
{
    auto mmCfg = CFG_NORM;
    mmCfg.isA2B2Shared = true;
    return mmCfg;
}

template <typename AType, typename BType, typename CType, typename BiasType>
class MatmulKernel {
public:
    __aicore__ inline MatmulKernel(){};
    /**
     * @brief  Initialization before process.
     * @param  a1: A matrix gm addr for the first matrix calculation.
     * @param  b1: B matrix gm addr for the first matrix calculation.
     * @param  a2: A matrix gm addr for the second matrix calculation.
     * @param  b2: B matrix gm addr for the second matrix calculation.
     * @param  bias: Bias matrix gm addr.
     * @param  c1: C matrix gm addr for the first matrix calculation.
     * @param  c2: C matrix gm addr for the second matrix calculation.
     * @param  tiling: Matmul tiling struct.
     * @retval None
     */
    __aicore__ inline void Init(GM_ADDR a1, GM_ADDR b1, GM_ADDR a2, GM_ADDR b2, GM_ADDR bias, GM_ADDR c1, GM_ADDR c2,
                                const TCubeTiling& tiling);
    /**
     * @brief  Process matrix calculation.
     * @retval None
     */
    __aicore__ inline void Process();

    constexpr static MatmulConfig CFG_NORM_A2B2SHARE = GetCustomCFG();
    // In the first matmul calculation, `a1 * b1 + bias = c1`.
    AscendC::Matmul<AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, AType, IS_TRANS_A>,
                    AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, BType, IS_TRANS_B>,
                    AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, CType>,
                    AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, BiasType>, CFG_NORM_A2B2SHARE>
        matmulObj1;
    // In the second matmul calculation, `a2 * b2 + bias = c2`.
    AscendC::Matmul<AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, AType, IS_TRANS_A>,
                    AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, BType, IS_TRANS_B>,
                    AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, CType>,
                    AscendC::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, BiasType>, CFG_NORM_A2B2SHARE>
        matmulObj2;

private:
    /**
     * @brief  Calculate the gm offset based on the blockIdx.
     * @param  blockIdx: Current Core blockidx.
     * @param  offsetA: Gm offset of A matrix.
     * @param  offsetB: Gm offset of B matrix.
     * @param  offsetC: Gm offset of C matrix.
     * @param  offsetBias: Gm offset of Bias matrix.
     * @retval None
     */
    __aicore__ inline void CalcOffset(int32_t blockIdx, int32_t& offsetA, int32_t& offsetB, int32_t& offsetC,
                                      int32_t& offsetBias);

    AscendC::GlobalTensor<AType> a1Global;
    AscendC::GlobalTensor<AType> a2Global;
    AscendC::GlobalTensor<BType> b1Global;
    AscendC::GlobalTensor<BType> b2Global;
    AscendC::GlobalTensor<CType> c1Global;
    AscendC::GlobalTensor<CType> c2Global;
    AscendC::GlobalTensor<BiasType> biasGlobal;
    TCubeTiling tiling;
};

template <typename AType, typename BType, typename CType, typename BiasType>
__aicore__ inline void MatmulKernel<AType, BType, CType, BiasType>::Init(GM_ADDR a1, GM_ADDR b1, GM_ADDR a2, GM_ADDR b2,
                                                                         GM_ADDR bias, GM_ADDR c1, GM_ADDR c2,
                                                                         const TCubeTiling& tiling)
{
    this->tiling = tiling;

    // In the first matmul calculation, `a1 * b1 + bias = c1`.
    a1Global.SetGlobalBuffer(reinterpret_cast<__gm__ AType*>(a1), tiling.M * tiling.Ka);
    b1Global.SetGlobalBuffer(reinterpret_cast<__gm__ BType*>(b1), tiling.Kb * tiling.N);
    c1Global.SetGlobalBuffer(reinterpret_cast<__gm__ CType*>(c1), tiling.M * tiling.N);
    // In the second matmul calculation, `a2 * b2 + bias = c2`.
    a2Global.SetGlobalBuffer(reinterpret_cast<__gm__ AType*>(a2), tiling.M * tiling.Ka);
    b2Global.SetGlobalBuffer(reinterpret_cast<__gm__ BType*>(b2), tiling.Kb * tiling.N);
    c2Global.SetGlobalBuffer(reinterpret_cast<__gm__ CType*>(c2), tiling.M * tiling.N);

    biasGlobal.SetGlobalBuffer(reinterpret_cast<__gm__ BiasType*>(bias), tiling.N);

    int32_t offsetA = 0;
    int32_t offsetB = 0;
    int32_t offsetC = 0;
    int32_t offsetBias = 0;
    CalcOffset(AscendC::GetBlockIdx(), offsetA, offsetB, offsetC, offsetBias);
    a1Global = a1Global[offsetA];
    b1Global = b1Global[offsetB];
    c1Global = c1Global[offsetC];
    a2Global = a2Global[offsetA];
    b2Global = b2Global[offsetB];
    c2Global = c2Global[offsetC];
    biasGlobal = biasGlobal[offsetBias];

    if (GetSysWorkSpacePtr() == nullptr) {
        return;
    }
}

template <typename AType, typename BType, typename CType, typename BiasType>
__aicore__ inline void MatmulKernel<AType, BType, CType, BiasType>::Process()
{
    matmulObj1.SetTensorA(a1Global);
    matmulObj1.SetTensorB(b1Global);
    matmulObj2.SetTensorA(a2Global);
    matmulObj2.SetTensorB(b2Global);
    if (tiling.isBias) {
        matmulObj1.SetBias(biasGlobal);
        matmulObj2.SetBias(biasGlobal);
    }
    matmulObj1.IterateAll(c1Global);
    matmulObj1.End();
    matmulObj2.IterateAll(c2Global);
    matmulObj2.End();
}

template <typename AType, typename BType, typename CType, typename BiasType>
__aicore__ inline void MatmulKernel<AType, BType, CType, BiasType>::CalcOffset(int32_t blockIdx, int32_t& offsetA,
                                                                               int32_t& offsetB, int32_t& offsetC,
                                                                               int32_t& offsetBias)
{
    TCubeTiling& param = this->tiling;

    auto temp0 = AscendC::Ceil(param.M, param.singleCoreM);
    auto temp1 = AscendC::Ceil(param.N, param.singleCoreN);

    auto mCoreIndex = (blockIdx % param.usedCoreNum) % temp0;
    auto nCoreIndex = (blockIdx % param.usedCoreNum) / temp0;
    auto subKIndex = blockIdx / param.usedCoreNum;

    offsetA = mCoreIndex * param.Ka * param.singleCoreM + subKIndex * param.singleCoreK;
    offsetB = subKIndex * param.singleCoreK * param.N + nCoreIndex * param.singleCoreN;
    offsetC = mCoreIndex * param.N * param.singleCoreM + nCoreIndex * param.singleCoreN;
    offsetBias = nCoreIndex * param.singleCoreN;
}

/**
 * @brief  matmul kernel function entry
 * @param  a: A matrix gm addr.
 * @param  b: B matrix gm addr.
 * @param  bias: bias matrix gm addr.
 * @param  c: C matrix gm addr.
 * @param  workspace: Temporary gm space addr required by matmul calc.
 * @param  tilingGm: Tiling data addr.
 * @retval None
 */
__global__ __aicore__ void matmul_custom(GM_ADDR a1, GM_ADDR b1, GM_ADDR a2, GM_ADDR b2, GM_ADDR bias, GM_ADDR c1,
                                         GM_ADDR c2, GM_ADDR workspace, GM_ADDR tilingGm)
{
    KERNEL_TASK_TYPE_DEFAULT(KERNEL_TYPE_AIC_ONLY);

    TCubeTiling tiling;
    CopyTiling(&tiling, tilingGm);

    MatmulKernel<half, half, float, float> matmulKernel;
    AscendC::TPipe pipe;
    REGIST_MATMUL_OBJ(&pipe, GetSysWorkSpacePtr(), matmulKernel.matmulObj1, &tiling, matmulKernel.matmulObj2, &tiling);

    matmulKernel.Init(a1, b1, a2, b2, bias, c1, c2, tiling);
    matmulKernel.Process();
}

void GenerateTiling(platform_ascendc::PlatformAscendC* ascendcPlatform, uint8_t* tilingBuf)
{
    optiling::TCubeTiling tilingData;
    matmul_tiling::MultiCoreMatmulTiling tilingApi(*ascendcPlatform);

    tilingApi.SetDim(ascendcPlatform->GetCoreNumAic());
    tilingApi.SetAType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT16,
                       IS_TRANS_A);
    tilingApi.SetBType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT16,
                       IS_TRANS_B);
    tilingApi.SetCType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND, matmul_tiling::DataType::DT_FLOAT);
    tilingApi.SetBiasType(matmul_tiling::TPosition::GM, matmul_tiling::CubeFormat::ND,
                          matmul_tiling::DataType::DT_FLOAT);

    tilingApi.SetOrgShape(M, N, K);
    tilingApi.SetShape(M, N, K);
    tilingApi.EnableBias(IS_BIAS);
    tilingApi.SetBufferSpace(-1, -1, -1);

    int64_t res = tilingApi.GetTiling(tilingData); // Get matmul tiling data.
    if (res == -1) {
        std::cout << "gen tiling failed" << std::endl;
    }
    uint32_t tcubeTilingSize = tilingData.GetDataSize();
    tilingData.SaveToBuffer(tilingBuf, tcubeTilingSize);
}

int32_t main(int32_t argc, char* argv[])
{
    auto ascendcPlatform = platform_ascendc::PlatformAscendCManager::GetInstance();

    size_t aFileSize = static_cast<size_t>(M * K) * sizeof(uint16_t); // uint16_t represent half
    size_t bFileSize = static_cast<size_t>(K * N) * sizeof(uint16_t); // uint16_t represent half
    size_t biasFileSize = static_cast<size_t>(sizeof(float) * N);
    size_t cFileSize = static_cast<size_t>(M * N) * sizeof(float);

    size_t userWorkspaceSize = 0;
    size_t systemWorkspaceSize = static_cast<size_t>(ascendcPlatform->GetLibApiWorkSpaceSize());
    size_t workspaceSize = userWorkspaceSize + systemWorkspaceSize;

    // matmul TCubeTiling
    size_t tilingFileSize = sizeof(TCubeTiling);
    uint8_t* tilingBuf = (uint8_t*)malloc(tilingFileSize);
    GenerateTiling(ascendcPlatform, tilingBuf);

    uint32_t blockDim = reinterpret_cast<TCubeTiling*>(tilingBuf)->usedCoreNum;

    int32_t deviceId = 0;
    aclrtStream stream = nullptr;
    aclrtContext context;

    aclInit(nullptr);
    aclrtSetDevice(deviceId);
    aclrtCreateContext(&context, deviceId);
    aclrtCreateStream(&stream);

    uint8_t* a1Host;
    uint8_t* a1Device;
    aclrtMallocHost((void**)(&a1Host), aFileSize);
    aclrtMalloc((void**)&a1Device, aFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/a1_gm.bin", aFileSize, a1Host, aFileSize);
    aclrtMemcpy(a1Device, aFileSize, a1Host, aFileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t* b1Host;
    uint8_t* b1Device;
    aclrtMallocHost((void**)(&b1Host), bFileSize);
    aclrtMalloc((void**)&b1Device, bFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/b1_gm.bin", bFileSize, b1Host, bFileSize);
    aclrtMemcpy(b1Device, bFileSize, b1Host, bFileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t* a2Host;
    uint8_t* a2Device;
    aclrtMallocHost((void**)(&a2Host), aFileSize);
    aclrtMalloc((void**)&a2Device, aFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/a2_gm.bin", aFileSize, a2Host, aFileSize);
    aclrtMemcpy(a2Device, aFileSize, a2Host, aFileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t* b2Host;
    uint8_t* b2Device;
    aclrtMallocHost((void**)(&b2Host), bFileSize);
    aclrtMalloc((void**)&b2Device, bFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/b2_gm.bin", bFileSize, b2Host, bFileSize);
    aclrtMemcpy(b2Device, bFileSize, b2Host, bFileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t* biasHost;
    uint8_t* biasDevice;
    if (IS_BIAS) {
        aclrtMallocHost((void**)(&biasHost), biasFileSize);
        aclrtMalloc((void**)&biasDevice, biasFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
        ReadFile("./input/bias_gm.bin", biasFileSize, biasHost, biasFileSize);
        aclrtMemcpy(biasDevice, biasFileSize, biasHost, biasFileSize, ACL_MEMCPY_HOST_TO_DEVICE);
    }

    uint8_t* c1Host;
    uint8_t* c1Device;
    aclrtMallocHost((void**)(&c1Host), cFileSize);
    aclrtMalloc((void**)&c1Device, cFileSize, ACL_MEM_MALLOC_HUGE_FIRST);

    uint8_t* c2Host;
    uint8_t* c2Device;
    aclrtMallocHost((void**)(&c2Host), cFileSize);
    aclrtMalloc((void**)&c2Device, cFileSize, ACL_MEM_MALLOC_HUGE_FIRST);

    uint8_t* workspaceDevice;
    aclrtMalloc((void**)&workspaceDevice, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);

    uint8_t* tilingHost;
    uint8_t* tilingDevice;
    aclrtMallocHost((void**)(&tilingHost), tilingFileSize);
    aclrtMalloc((void**)&tilingDevice, tilingFileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMemcpy(tilingHost, tilingFileSize, tilingBuf, tilingFileSize, ACL_MEMCPY_HOST_TO_HOST);
    aclrtMemcpy(tilingDevice, tilingFileSize, tilingHost, tilingFileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    matmul_custom<<<blockDim, nullptr, stream>>>(a1Device, b1Device, a2Device, b2Device, biasDevice, c1Device, c2Device,
                                                 workspaceDevice, tilingDevice);
    aclrtSynchronizeStream(stream);

    aclrtMemcpy(c1Host, cFileSize, c1Device, cFileSize, ACL_MEMCPY_DEVICE_TO_HOST);
    WriteFile("./output/output1.bin", c1Host, cFileSize);

    aclrtMemcpy(c2Host, cFileSize, c2Device, cFileSize, ACL_MEMCPY_DEVICE_TO_HOST);
    WriteFile("./output/output2.bin", c2Host, cFileSize);

    aclrtFree(a1Device);
    aclrtFreeHost(a1Host);
    aclrtFree(b1Device);
    aclrtFreeHost(b1Host);

    aclrtFree(a2Device);
    aclrtFreeHost(a2Host);
    aclrtFree(b2Device);
    aclrtFreeHost(b2Host);

    if (IS_BIAS) {
        aclrtFree(biasDevice);
        aclrtFreeHost(biasHost);
    }

    aclrtFree(c1Device);
    aclrtFreeHost(c1Host);
    aclrtFree(c2Device);
    aclrtFreeHost(c2Host);

    aclrtFree(workspaceDevice);
    aclrtFree(tilingDevice);
    aclrtFreeHost(tilingHost);

    aclrtDestroyStream(stream);
    aclrtResetDevice(deviceId);
    aclFinalize();

    free(tilingBuf);
    return 0;
}