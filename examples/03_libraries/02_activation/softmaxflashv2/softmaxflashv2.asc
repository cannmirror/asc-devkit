/**
* Copyright (c) 2025 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/


/* !
 * \file softmaxflashv2.asc
 * \brief
 */

#include "acl/acl.h"
#include "data_utils.h"
#include "kernel_operator.h"
#include "tiling/tiling_api.h"

class SoftmaxflashCustomTilingData {
public:
    uint32_t columnLength;
    uint32_t rowLength;
    uint32_t sharedTmpBufferSize;
    uint32_t usedNumBlocks;
    uint32_t coreRowNum;
    uint32_t tailCoreRowNum;
    uint32_t singleLoopCoreRowNum;
    uint32_t singleCoreLoopCount;
    uint32_t singleCoreLoopTail;
    uint32_t tailCoreSingleLoopCoreRowNum;
    uint32_t tailCoreSingleCoreLoopCount;
    uint32_t tailCoreSingleCoreLoopTail;
    uint32_t splitK;
    uint32_t loopK;
    uint32_t tailK;
    SoftMaxTiling softmaxTilingData;
};

namespace SoftmaxflashCustomTiling {
constexpr uint32_t SHARED_TMP_BUFFER_SIZE = 61440; // reserved tmpbuffer 60K for softmax compute

struct SingleCoreLoopParam {
    uint32_t singleLoopCoreRowNum{0}; // row num processed in single loop
    uint32_t singleCoreLoopCount{0};  // loop count in single loop
    uint32_t singleCoreLoopTail{0};   // row num of last loop in single core
    uint32_t splitK{0};               // single split num in k direction
    uint32_t loopK{0};                // loop count in k direction
    uint32_t tailK{0};                // tail num in k direction
};

SingleCoreLoopParam GetSingleCoreLoopParam(const uint32_t colNum, const uint32_t coreRowNum)
{
    //  Determine the params of single core based on the reduce axis length
    SingleCoreLoopParam singleCoreLoopParam;
    if (colNum >= 1024) { // reduce axis length >= 1024, set slice factor to 8
        singleCoreLoopParam.splitK = 1024;
        singleCoreLoopParam.loopK = colNum / 1024;
        singleCoreLoopParam.tailK = colNum % 1024;
        singleCoreLoopParam.singleLoopCoreRowNum = 8;
        singleCoreLoopParam.singleCoreLoopCount = coreRowNum / 8;
        singleCoreLoopParam.singleCoreLoopTail = coreRowNum % 8;
    } else if (colNum >= 512) { // reduce axis length < 1024 && >= 512, set slice factor to 16
        singleCoreLoopParam.splitK = 512;
        singleCoreLoopParam.loopK = colNum / 512;
        singleCoreLoopParam.tailK = colNum % 512;
        singleCoreLoopParam.singleLoopCoreRowNum = 16;
        singleCoreLoopParam.singleCoreLoopCount = coreRowNum / 16;
        singleCoreLoopParam.singleCoreLoopTail = coreRowNum % 16;
    } else if (colNum >= 128) { // reduce axis length < 512 && >= 128, set slice factor to 32
        singleCoreLoopParam.splitK = 128;
        singleCoreLoopParam.loopK = colNum / 128;
        singleCoreLoopParam.tailK = colNum % 128;
        singleCoreLoopParam.singleLoopCoreRowNum = 32;
        singleCoreLoopParam.singleCoreLoopCount = coreRowNum / 32;
        singleCoreLoopParam.singleCoreLoopTail = coreRowNum % 32;
    } else { // reduce axis length < 128 && >= 0, set slice factor to 64
        singleCoreLoopParam.splitK = colNum;
        singleCoreLoopParam.loopK = 1;
        singleCoreLoopParam.tailK = 0;
        singleCoreLoopParam.singleLoopCoreRowNum = 64;
        singleCoreLoopParam.singleCoreLoopCount = coreRowNum / 64;
        singleCoreLoopParam.singleCoreLoopTail = coreRowNum % 64;
    }
    return singleCoreLoopParam;
}

void ComputeTiling(const uint32_t rowNum, const uint32_t colNum, const uint32_t coreNum,
                   SoftmaxflashCustomTilingData* tiling)
{
    uint32_t localworkspaceSize = SHARED_TMP_BUFFER_SIZE;

    auto alignedRowNum = (rowNum + coreNum - 1) / coreNum * coreNum;
    auto coreRowNum = alignedRowNum / coreNum; // each core equal distribution
    auto tailCoreRowNum = rowNum % coreRowNum; // last core process the tail rownum
    auto usedNumBlocks = rowNum / coreRowNum;   // the core num used actually

    SingleCoreLoopParam mainCoreLoopParam = GetSingleCoreLoopParam(colNum, coreRowNum);
    SingleCoreLoopParam tailCoreLoopParam;
    if (usedNumBlocks == coreNum && tailCoreRowNum == 0) {
        tailCoreLoopParam = GetSingleCoreLoopParam(colNum, coreRowNum);
    } else {
        tailCoreLoopParam = GetSingleCoreLoopParam(colNum, tailCoreRowNum);
    }

    ge::Shape softmaxComputeShape({mainCoreLoopParam.singleLoopCoreRowNum, mainCoreLoopParam.splitK});
    uint32_t apiNeedMinTmpSize = 0;
    if (mainCoreLoopParam.singleLoopCoreRowNum % 8 == 0 && mainCoreLoopParam.splitK % 64 == 0) { // enable basicBlock
        apiNeedMinTmpSize =
            AscendC::GetSoftMaxFlashV2MinTmpSize(softmaxComputeShape, sizeof(float), sizeof(float), true, true);
    } else {
        apiNeedMinTmpSize =
            AscendC::GetSoftMaxFlashV2MinTmpSize(softmaxComputeShape, sizeof(float), sizeof(float), true, false);
    }
    if (apiNeedMinTmpSize > SHARED_TMP_BUFFER_SIZE) {
        localworkspaceSize = apiNeedMinTmpSize;
    } else {
        localworkspaceSize = SHARED_TMP_BUFFER_SIZE;
    }
    // get SoftMax Tiling
    if (mainCoreLoopParam.singleLoopCoreRowNum % 8 == 0 && mainCoreLoopParam.splitK % 64 == 0) { // enable basicBlock
        AscendC::SoftMaxFlashV2TilingFunc(softmaxComputeShape, sizeof(float), sizeof(float), localworkspaceSize,
                                          tiling->softmaxTilingData, true, true);
    } else {
        AscendC::SoftMaxFlashV2TilingFunc(softmaxComputeShape, sizeof(float), sizeof(float), localworkspaceSize,
                                          tiling->softmaxTilingData, true, false);
    }

    tiling->columnLength = colNum;
    tiling->rowLength = rowNum;
    tiling->sharedTmpBufferSize = localworkspaceSize;
    tiling->usedNumBlocks = usedNumBlocks;
    tiling->coreRowNum = coreRowNum;
    tiling->tailCoreRowNum = tailCoreRowNum;
    tiling->splitK = mainCoreLoopParam.splitK;
    tiling->loopK = mainCoreLoopParam.loopK;
    tiling->tailK = mainCoreLoopParam.tailK;

    tiling->singleLoopCoreRowNum = mainCoreLoopParam.singleLoopCoreRowNum;
    tiling->singleCoreLoopCount = mainCoreLoopParam.singleCoreLoopCount;
    tiling->singleCoreLoopTail = mainCoreLoopParam.singleCoreLoopTail;
    tiling->tailCoreSingleLoopCoreRowNum = tailCoreLoopParam.singleLoopCoreRowNum;
    tiling->tailCoreSingleCoreLoopCount = tailCoreLoopParam.singleCoreLoopCount;
    tiling->tailCoreSingleCoreLoopTail = tailCoreLoopParam.singleCoreLoopTail;
}
} // namespace SoftmaxflashCustomTiling

namespace MyCustomKernel {
constexpr int32_t BUFFER_NUM = 2;
constexpr uint32_t FLOAT_NUM_OF_SINGEL_BLOCK = 8;
constexpr uint32_t BASIC_BLOCK_ROW_FACTOR = 8;
constexpr uint32_t BASIC_BLOCK_COLUMN_FACTOR = 64;
constexpr uint32_t BASIC_BLOCK_MAX_COLUMN_LENGTH = 2048;

class KernelSoftmax {
public:
    __aicore__ inline KernelSoftmax() {}
    __aicore__ inline void InitTiling(const SoftmaxflashCustomTilingData& tilingData)
    {
        rowLength = tilingData.rowLength;
        sharedTmpBufferSize = tilingData.sharedTmpBufferSize;
        columnLength = tilingData.columnLength;
        usedNumBlocks = tilingData.usedNumBlocks;
        coreRowNum = tilingData.coreRowNum;
        softmaxTiling = tilingData.softmaxTilingData;
        singleLoopCoreRowNum = tilingData.singleLoopCoreRowNum;
        singleCoreLoopCount = tilingData.singleCoreLoopCount;
        leftRow = tilingData.singleCoreLoopTail;
        tailCoreSingleLoopCoreRowNum = tilingData.tailCoreSingleLoopCoreRowNum;
        tailCoreSingleCoreLoopCount = tilingData.tailCoreSingleCoreLoopCount;
        tailCoreSingleCoreLoopTail = tilingData.tailCoreSingleCoreLoopTail;
        splitK = tilingData.splitK;
        loopK = tilingData.loopK;
        tailK = tilingData.tailK;
    }

    __aicore__ inline void Init(GM_ADDR x, GM_ADDR max, GM_ADDR sum, const SoftmaxflashCustomTilingData& tilingData,
                                AscendC::TPipe* pipeIn)
    {
        pipe = pipeIn;
        ASSERT(AscendC::GetBlockNum() != 0 && "block dim can not be zero!");
        InitTiling(tilingData);

        if (AscendC::GetBlockIdx() == this->usedNumBlocks) { // tail core
            this->singleLoopCoreRowNum = this->tailCoreSingleLoopCoreRowNum;
            this->singleCoreLoopCount = this->tailCoreSingleCoreLoopCount;
            this->leftRow = this->tailCoreSingleCoreLoopTail;
        }

        this->blockLength = this->coreRowNum * this->columnLength;
        this->msLength = this->coreRowNum * FLOAT_NUM_OF_SINGEL_BLOCK; // max sum length per block process

        uint32_t offset1 = this->blockLength * AscendC::GetBlockIdx();
        uint32_t offset2 = this->msLength * AscendC::GetBlockIdx();

        xGm.SetGlobalBuffer((__gm__ float*)x + offset1, this->blockLength);
        maxGm.SetGlobalBuffer((__gm__ float*)max + offset2, this->msLength);
        sumGm.SetGlobalBuffer((__gm__ float*)sum + offset2, this->msLength);

        this->tileLength = this->singleLoopCoreRowNum * splitK;
        pipe->InitBuffer(queueX, BUFFER_NUM, this->tileLength * sizeof(float));

        this->msTileLength = this->singleLoopCoreRowNum * FLOAT_NUM_OF_SINGEL_BLOCK;
        pipe->InitBuffer(tbufMax, this->msTileLength * sizeof(float));
        pipe->InitBuffer(tbufSum, this->msTileLength * sizeof(float));
        pipe->InitBuffer(tbufExpmax, this->msTileLength * sizeof(float));
        maxLocal = tbufMax.Get<float>();
        sumLocal = tbufSum.Get<float>();
        expmaxLocal = tbufExpmax.Get<float>();

        pipe->InitBuffer(sharedTmpBuffer, sharedTmpBufferSize);
    }

    __aicore__ inline void Process()
    {
        if (AscendC::GetBlockIdx() > this->usedNumBlocks) {
            return;
        }

        for (int32_t i = 0; i < this->singleCoreLoopCount; i++) { // split M
            for (int32_t j = 0; j < this->loopK; j++) {           // split K
                CopyIn(i, j, this->singleLoopCoreRowNum, this->splitK);
                Compute(i, j, this->singleLoopCoreRowNum, this->splitK);
            }

            if (this->tailK > 0) {
                CopyIn(i, this->loopK, this->singleLoopCoreRowNum, this->tailK);
                Compute(i, this->loopK, this->singleLoopCoreRowNum, this->tailK);
            }
            event_t eventIdVToMte3 = static_cast<event_t>(GetTPipePtr()->FetchEventID(AscendC::HardEvent::V_MTE3));
            AscendC::SetFlag<AscendC::HardEvent::V_MTE3>(eventIdVToMte3);
            AscendC::WaitFlag<AscendC::HardEvent::V_MTE3>(eventIdVToMte3);
            // copy max sum to gm
            CopyOut(i, this->msTileLength);
        }
        event_t eventIdMte3ToV = static_cast<event_t>(GetTPipePtr()->FetchEventID(AscendC::HardEvent::MTE3_V));
        AscendC::SetFlag<AscendC::HardEvent::MTE3_V>(eventIdMte3ToV);
        AscendC::WaitFlag<AscendC::HardEvent::MTE3_V>(eventIdMte3ToV);

        if (this->leftRow > 0) {
            for (int32_t j = 0; j < this->loopK; j++) { // split K
                CopyIn(this->singleCoreLoopCount, j, this->leftRow, this->splitK);
                Compute(this->singleCoreLoopCount, j, this->leftRow, this->splitK);
            }

            if (this->tailK > 0) {
                CopyIn(this->singleCoreLoopCount, this->loopK, this->leftRow, this->tailK);
                Compute(this->singleCoreLoopCount, this->loopK, this->leftRow, this->tailK);
            }
            event_t eventIdVToMte3 = static_cast<event_t>(GetTPipePtr()->FetchEventID(AscendC::HardEvent::V_MTE3));
            AscendC::SetFlag<AscendC::HardEvent::V_MTE3>(eventIdVToMte3);
            AscendC::WaitFlag<AscendC::HardEvent::V_MTE3>(eventIdVToMte3);
            // copy max sum to gm
            uint32_t tailMsTileLength = this->leftRow * FLOAT_NUM_OF_SINGEL_BLOCK;
            CopyOut(this->singleCoreLoopCount, tailMsTileLength);
        }
    }

private:
    __aicore__ inline void CopyIn(uint32_t rowIndex, uint32_t kIndex, uint32_t rowNum, uint32_t columnNum)
    {
        AscendC::LocalTensor<float> xLocal = queueX.AllocTensor<float>();
        uint32_t offset = this->singleLoopCoreRowNum * this->columnLength;
        for (uint32_t i = 0; i < rowNum; i++) {
            AscendC::DataCopy(xLocal[i * columnNum],
                              xGm[rowIndex * offset + i * this->columnLength + kIndex * this->splitK], columnNum);
        }
        queueX.EnQue(xLocal);
    }

    __aicore__ inline void Compute(uint32_t rowIndex, uint32_t columnIndex, uint32_t rowNum, uint32_t columnNum)
    {
        AscendC::LocalTensor<float> xLocal = queueX.DeQue<float>();
        AscendC::LocalTensor<uint8_t> tmpBuffer = sharedTmpBuffer.Get<uint8_t>();

        AscendC::SoftMaxShapeInfo srcShape = {rowNum, columnNum, rowNum, columnNum};
        if (columnIndex == 0) { // isUpdate == false
            if (rowNum % BASIC_BLOCK_ROW_FACTOR == 0 && columnNum % BASIC_BLOCK_COLUMN_FACTOR == 0
                && columnNum < BASIC_BLOCK_MAX_COLUMN_LENGTH) {
                AscendC::SoftmaxFlashV2<float, false, true, true>(xLocal, sumLocal, maxLocal, xLocal, expmaxLocal,
                                                                  sumLocal, maxLocal, tmpBuffer, softmaxTiling,
                                                                  srcShape);
            } else {
                AscendC::SoftmaxFlashV2<float, false, true, false>(xLocal, sumLocal, maxLocal, xLocal, expmaxLocal,
                                                                   sumLocal, maxLocal, tmpBuffer, softmaxTiling,
                                                                   srcShape);
            }
        } else {
            if (rowNum % BASIC_BLOCK_ROW_FACTOR == 0 && columnNum % BASIC_BLOCK_COLUMN_FACTOR == 0
                && columnNum < BASIC_BLOCK_MAX_COLUMN_LENGTH) {
                AscendC::SoftmaxFlashV2<float, true, true, true>(xLocal, sumLocal, maxLocal, xLocal, expmaxLocal,
                                                                 sumLocal, maxLocal, tmpBuffer, softmaxTiling,
                                                                 srcShape);
            } else {
                AscendC::SoftmaxFlashV2<float, true, true, false>(xLocal, sumLocal, maxLocal, xLocal, expmaxLocal,
                                                                  sumLocal, maxLocal, tmpBuffer, softmaxTiling,
                                                                  srcShape);
            }
        }
        queueX.FreeTensor(xLocal);
    }

    __aicore__ inline void CopyOut(uint32_t progress, uint32_t count)
    {
        AscendC::DataCopy(maxGm[progress * this->msTileLength], maxLocal, count);
        AscendC::DataCopy(sumGm[progress * this->msTileLength], sumLocal, count);
    }

private:
    AscendC::TPipe* pipe;
    AscendC::TBuf<AscendC::TPosition::VECCALC> sharedTmpBuffer;
    AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> queueX;
    AscendC::TBuf<AscendC::TPosition::VECCALC> tbufMax, tbufSum, tbufExpmax;
    AscendC::GlobalTensor<float> xGm;
    AscendC::GlobalTensor<float> maxGm;
    AscendC::GlobalTensor<float> sumGm;
    AscendC::LocalTensor<float> maxLocal;
    AscendC::LocalTensor<float> sumLocal;
    AscendC::LocalTensor<float> expmaxLocal;

    uint32_t blockLength = 0;
    uint32_t usedNumBlocks = 0;
    uint32_t msLength = 0;
    uint32_t rowLength = 0;
    uint32_t columnLength = 0;
    uint32_t coreRowNum = 0;
    uint32_t tileLength = 0;
    uint32_t msTileLength = 0;
    uint32_t loopCount = 0;
    uint32_t sharedTmpBufferSize = 0;
    uint32_t singleLoopCoreRowNum = 0;
    uint32_t singleCoreLoopCount = 0;
    uint32_t leftRow = 0;
    uint32_t tailCoreSingleLoopCoreRowNum = 0;
    uint32_t tailCoreSingleCoreLoopCount = 0;
    uint32_t tailCoreSingleCoreLoopTail = 0;
    uint32_t splitK = 0;
    uint32_t loopK = 0;
    uint32_t tailK = 0;
    SoftMaxTiling softmaxTiling;
};
} // namespace MyCustomKernel

void GenerateTiling(const uint32_t rowNum, const uint32_t colNum, const uint32_t coreNum, const uint32_t tilingSize,
                    uint8_t* tilingBuffer)
{
    SoftmaxflashCustomTilingData tiling;
    SoftmaxflashCustomTiling::ComputeTiling(rowNum, colNum, coreNum, &tiling);

    memcpy_s(tilingBuffer, sizeof(SoftmaxflashCustomTilingData), &tiling, sizeof(SoftmaxflashCustomTilingData));
}

__aicore__ inline void CopyTiling(SoftmaxflashCustomTilingData* tiling, GM_ADDR tilingGM)
{
    uint32_t* ptr = reinterpret_cast<uint32_t*>(tiling);
    auto tiling32 = reinterpret_cast<__gm__ uint32_t*>(tilingGM);

    for (int i = 0; i < sizeof(SoftmaxflashCustomTilingData) / sizeof(uint32_t); i++, ptr++) { *ptr = *(tiling32 + i); }
    return;
}

__global__ __vector__ void softmaxflashv2_custom(GM_ADDR x, GM_ADDR max, GM_ADDR sum, GM_ADDR workspace, GM_ADDR tiling)
{
    AscendC::TPipe pipe;
    SoftmaxflashCustomTilingData tilingData;
    CopyTiling(&tilingData, tiling);
    MyCustomKernel::KernelSoftmax op;
    op.Init(x, max, sum, tilingData, &pipe);
    op.Process();
}

constexpr uint32_t ROW_NUM = 960;
constexpr uint32_t COLUMN_NUM = 960;
constexpr uint32_t USED_CORE_NUM = 40;
constexpr uint32_t WORKSPACE_SIZE = 1024;
constexpr uint32_t TILINGDATA_SIZE = 32; // Element count of struct SoftmaxflashCustomTilingData
constexpr uint32_t FLOAT_NUM_PER_BLOCK = 8;

extern void GenerateTiling(const uint32_t m, const uint32_t k, const uint32_t coreNum, const uint32_t tilingSize,
                           uint8_t* tilingData);

static int64_t CompareResult(void* outputData, const int64_t outSize)
{
    void* goldenData;
    aclrtMallocHost((void**)(&goldenData), outSize);
    size_t goldenSize = outSize;
    bool ret = ReadFile("./output/golden_sum.bin", goldenSize, goldenData, goldenSize);
    if (ret) {
        printf("ReadFile golden success!\n");
    } else {
        aclrtFreeHost(goldenData);
        return -1;
    }
    constexpr float EPS = 1e-5;
    int64_t wrongNum = 0;

    for (int i = 0; i < outSize / sizeof(float); i++) {
        float a = ((float*)outputData)[i];
        float b = ((float*)goldenData)[i];
        float ae = std::abs(a - b);
        float re = ae / std::abs(b);
        if (ae > EPS && re > EPS) {
            printf("CompareResult failed output is %lf, golden is %lf\n", a, b);
            wrongNum++;
        }
    }
    aclrtFreeHost(goldenData);
    return wrongNum;
}

int32_t main(int32_t argc, char* argv[])
{
    size_t inputSize = ROW_NUM * ROW_NUM * sizeof(float);
    size_t workspaceSize = WORKSPACE_SIZE * sizeof(float);
    size_t tilingSize = TILINGDATA_SIZE * sizeof(uint32_t);
    size_t outputMaxSize = ROW_NUM * FLOAT_NUM_PER_BLOCK * sizeof(float);
    size_t outputSumSize = ROW_NUM * FLOAT_NUM_PER_BLOCK * sizeof(float);
    int64_t wrongNum = -1;

    // Initialize resources
    aclInit(nullptr);
    aclrtContext context;
    int32_t deviceId = 0;
    aclrtSetDevice(deviceId);
    aclrtCreateContext(&context, deviceId);
    aclrtStream stream = nullptr;
    aclrtCreateStream(&stream);

    uint8_t *xHost, *maxHost, *sumHost, *workspaceHost, *tilingHost;
    uint8_t *xDevice, *maxDevice, *sumDevice, *workspaceDevice, *tilingDevice;

    // Allocate host memory and device memory
    aclrtMallocHost((void**)(&xHost), inputSize);
    aclrtMallocHost((void**)(&maxHost), outputMaxSize);
    aclrtMallocHost((void**)(&sumHost), outputSumSize);
    aclrtMallocHost((void**)(&workspaceHost), workspaceSize);
    aclrtMallocHost((void**)(&tilingHost), tilingSize);
    aclrtMalloc((void**)&xDevice, inputSize, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMalloc((void**)&maxDevice, outputMaxSize, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMalloc((void**)&sumDevice, outputSumSize, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMalloc((void**)&workspaceDevice, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMalloc((void**)&tilingDevice, tilingSize, ACL_MEM_MALLOC_HUGE_FIRST);

    ReadFile("./input/input_x.bin", inputSize, xHost, inputSize);
    ReadFile("./input/workspace.bin", workspaceSize, workspaceHost, workspaceSize);

    GenerateTiling(ROW_NUM, COLUMN_NUM, USED_CORE_NUM, tilingSize, tilingHost);

    // Copy host memory to device memory
    aclrtMemcpy(xDevice, inputSize, xHost, inputSize, ACL_MEMCPY_HOST_TO_DEVICE);
    aclrtMemcpy(workspaceDevice, workspaceSize, workspaceHost, workspaceSize, ACL_MEMCPY_HOST_TO_DEVICE);
    aclrtMemcpy(tilingDevice, tilingSize, tilingHost, tilingSize, ACL_MEMCPY_HOST_TO_DEVICE);

    // Execute the kernel
    softmaxflashv2_custom<<<USED_CORE_NUM, nullptr, stream>>>(xDevice, maxDevice, sumDevice, workspaceDevice,
                                                              tilingDevice);

    // Wait for the stop event to complete
    aclrtSynchronizeStream(stream);

    // Copy result to host memory and write to output file
    aclrtMemcpy(maxHost, outputMaxSize, maxDevice, outputMaxSize, ACL_MEMCPY_DEVICE_TO_HOST);
    aclrtMemcpy(sumHost, outputSumSize, sumDevice, outputSumSize, ACL_MEMCPY_DEVICE_TO_HOST);
    WriteFile("./output/output_max.bin", maxHost, outputMaxSize);
    WriteFile("./output/output_sum.bin", sumHost, outputSumSize);

    // Compare the result with the golden result
    wrongNum = CompareResult(sumHost, outputSumSize); // softmaxflash just need to compare sum

    // Clean up memory
    aclrtFree(xDevice);
    aclrtFree(maxDevice);
    aclrtFree(sumDevice);
    aclrtFree(workspaceDevice);
    aclrtFree(tilingDevice);
    aclrtFreeHost(xHost);
    aclrtFreeHost(maxHost);
    aclrtFreeHost(sumHost);
    aclrtFreeHost(workspaceHost);
    aclrtFreeHost(tilingHost);

    aclrtDestroyStream(stream);
    aclrtDestroyContext(context);
    aclrtResetDevice(deviceId);
    aclFinalize();
  
    if (wrongNum != 0) {
        printf("test failed!\n");
    } else {
        printf("test pass!\n");
    }
    return 0;
}