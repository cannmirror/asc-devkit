/**
* Copyright (c) 2026 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/


/* !
 * \file reduce.asc
 * \brief
 */

#include "acl/acl.h"
#include "data_utils.h"
#include "kernel_operator.h"
#include "tiling/tiling_api.h"

struct ReduceCustomTilingData {
    uint32_t totalLength;
    uint32_t outLength;
};

constexpr uint32_t REDUCE_TILING_1 = 1;
constexpr uint32_t REDUCE_TILING_2 = 2;
constexpr uint32_t REDUCE_TILING_3 = 3;
constexpr uint32_t REDUCE_TILING_4 = 4;
constexpr uint32_t REDUCE_TILING_5 = 5;


template <typename T>
class KernelReduce {
static constexpr uint32_t DEFAULT_BLK_STRIDE = 1;
static constexpr uint32_t DEFAULT_REP_STRIDE = 8;
static constexpr uint32_t REP_LEN = 256;
static constexpr uint32_t BLK_LEN = 32;
static constexpr uint32_t ONE_REPEAT_FLOAT_SIZE = REP_LEN / 4;
static constexpr uint32_t BINARY_BOUNDARY = DEFAULT_REP_STRIDE * 2;

public:
    __aicore__ inline KernelReduce() {}
    __aicore__ inline void Init(GM_ADDR x, GM_ADDR z, uint32_t totalLength, uint32_t outLength, AscendC::TPipe* pipeIn)
    {
        pipe = pipeIn;
        this->totalLength = totalLength;
        this->outLength = outLength;

        xGm.SetGlobalBuffer((__gm__ T*)x, totalLength);
        zGm.SetGlobalBuffer((__gm__ T*)z, outLength);
        pipe->InitBuffer(inQueueX, 1, totalLength * sizeof(T));
        pipe->InitBuffer(outQueueZ, 1, outLength * sizeof(T));
    }

    template <size_t ComputeKey = 0>
    __aicore__ inline void Compute()
    {
        if constexpr (ComputeKey == REDUCE_TILING_1) {
            Compute1();
        } else if constexpr (ComputeKey == REDUCE_TILING_2) {
            Compute2();
        } else if constexpr (ComputeKey == REDUCE_TILING_3) {
            Compute3();
        } else if constexpr (ComputeKey == REDUCE_TILING_4) {
            Compute4();
        } else if constexpr (ComputeKey == REDUCE_TILING_5) {
            Compute5();
        }
    }

    template <size_t ComputeKey = 0>
    __aicore__ inline void Process()
    {
        CopyIn();
        Compute<ComputeKey>();
        CopyOut();
    }

private:
    __aicore__ inline void CopyIn()
    {
        AscendC::LocalTensor<T> xLocal = inQueueX.AllocTensor<T>();
        AscendC::DataCopy(xLocal, xGm, totalLength);
        inQueueX.EnQue(xLocal);
    }
    // Only WholeReduceSum is used under 256B.
    __aicore__ inline void Compute1()
    {
        AscendC::LocalTensor<T> xLocal = inQueueX.DeQue<T>();
        AscendC::LocalTensor<T> zLocal = outQueueZ.AllocTensor<T>();
        const T zero = 0;
        AscendC::Duplicate<T>(zLocal, zero, outLength);

        constexpr int64_t maskLen = REP_LEN / sizeof(T);
        AscendC::WholeReduceSum<T>(zLocal, xLocal, maskLen, 1, DEFAULT_BLK_STRIDE, DEFAULT_BLK_STRIDE,
                                   DEFAULT_REP_STRIDE);

        outQueueZ.EnQue<T>(zLocal);
        inQueueX.FreeTensor(xLocal);
    }
    // One WholeReduceSum and one BlockReduceSum are used in (256B,2KB](for float input) and (256B,4KB](for half input).
    __aicore__ inline void Compute2()
    {
        AscendC::LocalTensor<T> xLocal = inQueueX.DeQue<T>();
        AscendC::LocalTensor<T> zLocal = outQueueZ.AllocTensor<T>();
        const T zero = 0;
        AscendC::Duplicate<T>(zLocal, zero, outLength);

        pipe->InitBuffer(calcBuf, totalLength * sizeof(T));
        AscendC::LocalTensor<T> tempTensor1 = calcBuf.Get<T>();
        constexpr uint32_t c0Count = BLK_LEN / sizeof(T);
        const uint32_t blockNum0 = (totalLength + c0Count - 1) / c0Count;

        AscendC::SetMaskCount();
        AscendC::SetVectorMask<T>(0, totalLength);
        AscendC::BlockReduceSum<T, false>(tempTensor1, xLocal, 1, AscendC::MASK_PLACEHOLDER, DEFAULT_BLK_STRIDE,
                                          DEFAULT_BLK_STRIDE, DEFAULT_REP_STRIDE);
        AscendC::PipeBarrier<PIPE_V>();
        AscendC::SetVectorMask<T>(0, blockNum0);
        AscendC::WholeReduceSum<T, false>(zLocal, tempTensor1, 1, AscendC::MASK_PLACEHOLDER, DEFAULT_BLK_STRIDE,
                                          DEFAULT_BLK_STRIDE, DEFAULT_REP_STRIDE);
        AscendC::PipeBarrier<PIPE_V>();
        AscendC::SetMaskNorm();

        outQueueZ.EnQue<T>(zLocal);
        inQueueX.FreeTensor(xLocal);
    }
    // Two WholeReduceSum are used in (2KB,16KB](for float input) and (4KB,32KB](for half input).
    __aicore__ inline void Compute3()
    {
        AscendC::LocalTensor<T> xLocal = inQueueX.DeQue<T>();
        AscendC::LocalTensor<T> zLocal = outQueueZ.AllocTensor<T>();
        const T zero = 0;
        AscendC::Duplicate<T>(zLocal, zero, outLength);

        pipe->InitBuffer(calcBuf, totalLength * sizeof(T));
        AscendC::LocalTensor<T> tempTensor1 = calcBuf.Get<T>();
        const uint32_t repeatNum = (totalLength * sizeof(T) + REP_LEN - 1) / REP_LEN;

        AscendC::SetMaskCount();
        AscendC::SetVectorMask<T>(0, totalLength);
        AscendC::WholeReduceSum<T, false>(tempTensor1, xLocal, 1, AscendC::MASK_PLACEHOLDER, DEFAULT_BLK_STRIDE,
                                          DEFAULT_BLK_STRIDE, DEFAULT_REP_STRIDE);
        AscendC::PipeBarrier<PIPE_V>();
        AscendC::SetVectorMask<T>(0, repeatNum);
        AscendC::WholeReduceSum<T, false>(zLocal, tempTensor1, 1, AscendC::MASK_PLACEHOLDER, DEFAULT_BLK_STRIDE,
                                          DEFAULT_BLK_STRIDE, DEFAULT_REP_STRIDE);
        AscendC::PipeBarrier<PIPE_V>();
        AscendC::SetMaskNorm();

        outQueueZ.EnQue<T>(zLocal);
        inQueueX.FreeTensor(xLocal);
    }

    __aicore__ inline void Compute4()
    {
        AscendC::LocalTensor<T> xLocal = inQueueX.DeQue<T>();
        AscendC::LocalTensor<T> zLocal = outQueueZ.AllocTensor<T>();

        int64_t start = AscendC::GetSystemCycle();
        WholeReduceSumImpl(zLocal, xLocal, 1, totalLength);
        int64_t runCycle = AscendC::GetSystemCycle() - start;

        outQueueZ.EnQue<T>(zLocal);
        inQueueX.FreeTensor(xLocal);
    }

    __aicore__ inline void Compute5()
    {
        AscendC::LocalTensor<T> xLocal = inQueueX.DeQue<T>();
        AscendC::LocalTensor<T> zLocal = outQueueZ.AllocTensor<T>();

        int64_t start = AscendC::GetSystemCycle();
        BinaryReduceSumImpl(zLocal, xLocal, 1, totalLength);
        int64_t runCycle = AscendC::GetSystemCycle() - start;

        outQueueZ.EnQue<T>(zLocal);
        inQueueX.FreeTensor(xLocal);
    }

    __aicore__ inline void CopyOut()
    {
        AscendC::LocalTensor<T> zLocal = outQueueZ.DeQue<T>();
        AscendC::DataCopy(zGm, zLocal, this->outLength);
        outQueueZ.FreeTensor(zLocal);
    }

    __aicore__ inline void WholeReduceSumImpl(const AscendC::LocalTensor<float>& dst,
                                              const AscendC::LocalTensor<float>& src, const uint32_t bsLength,
                                              const uint32_t hLength)
    { 
        AscendC::SetMaskCount();
        for (uint32_t i = 0; i < bsLength; i++) {
            uint32_t totalNum = hLength;
            AscendC::LocalTensor<float> srcTmp = src[i * hLength];
            AscendC::LocalTensor<float> dstTmp = dst[i * hLength];
            while (totalNum > 1) {
                AscendC::SetVectorMask<uint8_t, AscendC::MaskMode::COUNTER>(0, totalNum);
                AscendC::WholeReduceSum<float, false>(dstTmp, srcTmp, AscendC::MASK_PLACEHOLDER, 1, DEFAULT_BLK_STRIDE,
                    DEFAULT_BLK_STRIDE, DEFAULT_REP_STRIDE);
                AscendC::PipeBarrier<PIPE_V>();
                totalNum = AscendC::DivCeil(totalNum, ONE_REPEAT_FLOAT_SIZE);
                srcTmp = dstTmp;
            }
        }
        AscendC::ResetMask();
        AscendC::SetMaskNorm();
    }

    __aicore__ inline void BinaryReduceSumImpl(const AscendC::LocalTensor<float>& dst,
                                               const AscendC::LocalTensor<float>& src, const uint32_t bsLength,
                                               const uint32_t hLength)
    {
        AscendC::BinaryRepeatParams binaryParams;
        AscendC::UnaryRepeatParams unaryParams;
        AscendC::SetMaskCount();
        for (uint32_t i = 0; i < bsLength; i++) {
            uint32_t totalNum = hLength;
            AscendC::LocalTensor<float> srcTmp = src[i * hLength];
            AscendC::LocalTensor<float> dstTmp = dst[i * hLength];
            while (totalNum > ONE_REPEAT_FLOAT_SIZE) {
                uint32_t halfNum = AscendC::DivCeil(totalNum, BINARY_BOUNDARY) * DEFAULT_REP_STRIDE;
                AscendC::SetVectorMask<uint8_t, AscendC::MaskMode::COUNTER>(0, totalNum - halfNum);
                AscendC::Add<float, false>(dstTmp, srcTmp, srcTmp[halfNum], AscendC::MASK_PLACEHOLDER, 1, binaryParams);
                AscendC::PipeBarrier<PIPE_V>();
                totalNum = halfNum;
                srcTmp = dstTmp;
            }
            AscendC::SetVectorMask<uint8_t, AscendC::MaskMode::COUNTER>(0, totalNum);
            AscendC::WholeReduceSum<float, false>(dstTmp, srcTmp, AscendC::MASK_PLACEHOLDER, 1, DEFAULT_BLK_STRIDE,
                DEFAULT_BLK_STRIDE, DEFAULT_REP_STRIDE);
            AscendC::PipeBarrier<PIPE_V>();
        }
        AscendC::ResetMask();
        AscendC::SetMaskNorm();
    }

private:
    AscendC::TPipe* pipe;
    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;
    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueZ;
    AscendC::TBuf<AscendC::TPosition::VECCALC> calcBuf;
    AscendC::GlobalTensor<T> xGm;
    AscendC::GlobalTensor<T> zGm;
    uint32_t totalLength;
    uint32_t outLength;
};

extern "C" __global__ __vector__ void reduce_custom(GM_ADDR x, GM_ADDR z, ReduceCustomTilingData tiling)
{
    AscendC::TPipe pipe;
    KernelReduce<float> op;
    op.Init(x, z, tiling.totalLength, tiling.outLength, &pipe);
    if ((tiling.totalLength * sizeof(float)) <= 256) {
        op.Process<REDUCE_TILING_1>();
    } else if ((tiling.totalLength * sizeof(float)) <= 2048) {
        op.Process<REDUCE_TILING_2>();
    } else if ((tiling.totalLength * sizeof(float)) <= 16384) {
        op.Process<REDUCE_TILING_3>();
    } else if (tiling.totalLength == 10000) {
        op.Process<REDUCE_TILING_4>();
    } else if (tiling.totalLength == 20000) {
        op.Process<REDUCE_TILING_5>();
    }
}

static bool CompareResult(const void* outputData, uint32_t outSize)
{
    void* goldenData;
    aclrtMallocHost((void**)(&goldenData), outSize);
    size_t goldenSize = outSize;
    bool ret = ReadFile("./output/golden.bin", goldenSize, goldenData, goldenSize);
    if (ret) {
        printf("ReadFile golden.bin success!\n");
    } else {
        printf("test failed!\n");
        return false;
    }
    constexpr float EPS = 1e-4;
    int64_t wrongNum = 0;

    for (size_t i = 0; i < 1; i++) {
        float a = (reinterpret_cast<const float*>(outputData))[i];
        float b = (reinterpret_cast<const float*>(goldenData))[i];
        float ae = std::abs(a - b);
        float re = ae / std::abs(b + EPS);
        if (ae > EPS && re > EPS) {
            printf("CompareResult golden.bin failed output is %lf, golden is %lf\n", a, b);
            wrongNum++;
        }
    }
    aclrtFreeHost(goldenData);
    if (wrongNum != 0) {
        printf("wrongNum: %ld\n", wrongNum);
        return false;
    } else {
        printf("CompareResult golden.bin success!\n");
        return true;
    }
}

int32_t main(int32_t argc, char* argv[])
{
    size_t param1FileSize = 4096 * sizeof(float);
    size_t param2FileSize = 32 * sizeof(float);
    ReduceCustomTilingData tiling = {4096, 32};
    uint32_t numBlocks = 1;

    aclInit(nullptr);
    aclrtContext context;
    int32_t deviceId = 0;
    aclrtSetDevice(deviceId);
    aclrtCreateContext(&context, deviceId);
    aclrtStream stream = nullptr;
    aclrtCreateStream(&stream);

    uint8_t* param1Host;
    uint8_t* param1Device;
    aclrtMallocHost((void**)(&param1Host), param1FileSize);
    aclrtMalloc((void**)&param1Device, param1FileSize, ACL_MEM_MALLOC_HUGE_FIRST);
    ReadFile("./input/input_x.bin", param1FileSize, param1Host, param1FileSize);
    aclrtMemcpy(param1Device, param1FileSize, param1Host, param1FileSize, ACL_MEMCPY_HOST_TO_DEVICE);

    uint8_t* param2Host;
    uint8_t* param2Device;
    aclrtMallocHost((void**)(&param2Host), param2FileSize);
    aclrtMalloc((void**)&param2Device, param2FileSize, ACL_MEM_MALLOC_HUGE_FIRST);

    reduce_custom<<<numBlocks, nullptr, stream>>>(param1Device, param2Device, tiling);
    aclrtSynchronizeStream(stream);

    aclrtFree(param1Device);
    aclrtFreeHost(param1Host);

    aclrtMemcpy(param2Host, param2FileSize, param2Device, param2FileSize, ACL_MEMCPY_DEVICE_TO_HOST);
    WriteFile("./output/output.bin", param2Host, param2FileSize);

    bool goldenResult = true;
    goldenResult = CompareResult(param2Host, param2FileSize);
    if (goldenResult) {
        printf("test pass!\n");
    } else {
        printf("test failed!\n");
    }

    aclrtFree(param2Device);
    aclrtFreeHost(param2Host);

    aclrtDestroyStream(stream);
    aclrtDestroyContext(context);
    aclrtResetDevice(deviceId);
    aclFinalize();

    return 0;
}