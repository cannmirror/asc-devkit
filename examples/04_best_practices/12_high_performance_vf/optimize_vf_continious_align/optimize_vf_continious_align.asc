/**
* Copyright (c) 2025 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/


#include <vector>
#include <iostream>
#include <iterator>
#include "acl/acl.h"
#include "kernel_operator.h"

template <typename T>
__simd_vf__ inline void LoadVF(__ubuf__ T* srcAddr, __ubuf__ T* dstAddr, uint16_t postUpdateStride, uint32_t repeatTimes,
                               uint16_t count)
{
    AscendC::MicroAPI::RegTensor<T> srcReg, dstReg;
    AscendC::MicroAPI::UnalignRegForLoad ureg0;
    AscendC::MicroAPI::UnalignRegForStore ureg1;
    AscendC::MicroAPI::LoadUnAlignPre(ureg0, srcAddr);
    for (uint16_t i = 0; i < repeatTimes; ++i) {
        AscendC::MicroAPI::LoadUnAlign(srcReg, ureg0, srcAddr + i * postUpdateStride);
        AscendC::MicroAPI::StoreUnAlign(dstAddr, srcReg, ureg1, postUpdateStride);
    }
    AscendC::MicroAPI::StoreUnAlignPost(dstAddr, ureg1, 0);
}

template <typename T>
class Kernel {
public:
    __aicore__ inline void Init(GM_ADDR x, GM_ADDR y, uint32_t count, AscendC::TPipe* pipeIn)
    {
        this->pipe = pipeIn;
        this->count = count;
        this->xGm.SetGlobalBuffer(reinterpret_cast<__gm__ T*>(x));
        this->yGm.SetGlobalBuffer(reinterpret_cast<__gm__ T*>(y));
        this->pipe->InitBuffer(inQueueX, 1, sizeof(T) * count);
        this->pipe->InitBuffer(outQueueY, 1, sizeof(T) * count);
    }
    __aicore__ inline void CopyIn()
    {
        AscendC::LocalTensor<T> xLocal = inQueueX.AllocTensor<T>();
        AscendC::Duplicate<T>(xLocal, 0, count);
        AscendC::DataCopy(xLocal, xGm, count);
        inQueueX.EnQue<T>(xLocal);
    }
    __aicore__ inline void Compute()
    {
        AscendC::LocalTensor<T> xLocal = inQueueX.DeQue<T>();
        AscendC::LocalTensor<T> yLocal = outQueueY.AllocTensor<T>();
        __ubuf__ T* srcAddr = reinterpret_cast<__ubuf__ T*>(xLocal.GetPhyAddr());
        __ubuf__ T* dstAddr = reinterpret_cast<__ubuf__ T*>(yLocal.GetPhyAddr());
        constexpr uint32_t oneRepeatSize = AscendC::GetVecLen() / sizeof(T);
        uint16_t repeatTimes = AscendC::CeilDivision(count, oneRepeatSize);
        AscendC::VF_CALL<LoadVF<T>>(srcAddr, dstAddr, oneRepeatSize, repeatTimes, count);
        outQueueY.EnQue<T>(yLocal);
    }
    __aicore__ inline void CopyOut()
    {
        AscendC::LocalTensor<T> yLocal = outQueueY.DeQue<T>();
        AscendC::DataCopy(yGm, yLocal, count);
    }
    __aicore__ inline void Process()
    {
        CopyIn();
        Compute();
        CopyOut();
    }

private:
    AscendC::TPipe* pipe = nullptr;
    uint32_t count;
    AscendC::GlobalTensor<T> xGm;
    AscendC::GlobalTensor<T> yGm;
    AscendC::TQue<AscendC::TPosition::VECIN, 1> inQueueX;
    AscendC::TQue<AscendC::TPosition::VECOUT, 1> outQueueY;
};

__global__ __aicore__ void optimize_vf_continious_align_kernel(GM_ADDR x, GM_ADDR y)
{
    AscendC::TPipe pipe;
    Kernel<float> kernel;
    kernel.Init(x, y, 1024, &pipe);
    kernel.Process();
}

std::vector<float> optimize_vf_continious_align(std::vector<float>& input)
{
    uint32_t input_length = input.size();
    uint32_t blockDim = 1;
    aclInit(nullptr);
    int32_t deviceId = 0;
    aclrtSetDevice(deviceId);
    aclrtStream stream = nullptr;
    aclrtCreateStream(&stream);
    size_t aInputByteSize = static_cast<size_t>(1) * input_length * sizeof(float);
    size_t outputByteSize = static_cast<size_t>(1) * input_length * sizeof(float);
    uint8_t *xHost, *yHost;
    uint8_t *xDevice, *yDevice;
    aclrtMallocHost((void**)(&xHost), aInputByteSize);
    aclrtMallocHost((void**)(&yHost), outputByteSize);
    aclrtMalloc((void**)&xDevice, aInputByteSize, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMalloc((void**)&yDevice, outputByteSize, ACL_MEM_MALLOC_HUGE_FIRST);
    xHost = reinterpret_cast<uint8_t *>(input.data());
    aclrtMemcpy(xDevice, aInputByteSize, xHost, aInputByteSize, ACL_MEMCPY_HOST_TO_DEVICE);
    optimize_vf_continious_align_kernel<<<blockDim, nullptr, stream>>>(xDevice, yDevice);
    aclrtSynchronizeStream(stream);
    aclrtMemcpy(yHost, outputByteSize, yDevice, outputByteSize, ACL_MEMCPY_DEVICE_TO_HOST);
    std::vector<float> output((float*)yHost, (float*)(yHost + outputByteSize));
    aclrtFree(xDevice);
    aclrtFree(yDevice);
    aclrtFreeHost(xHost);
    aclrtFreeHost(yHost);
    aclrtDestroyStream(stream);
    aclrtResetDevice(deviceId);
    aclFinalize();
    return output;
}

uint32_t verify_result(std::vector<float>& output, std::vector<float>& golden)
{
    auto print_tensor = [](std::vector<float>& tensor, const char* name) {
        constexpr size_t max_print_size = 20;
        std::cout << name << ": ";
        std::copy(tensor.begin(), tensor.begin() + std::min(tensor.size(), max_print_size),
            std::ostream_iterator<float>(std::cout, " "));
        if (tensor.size() > max_print_size) {
            std::cout << "...";
        }
        std::cout << std::endl;
    };
    print_tensor(output, "Output");
    print_tensor(golden, "Golden");
    if (std::equal(output.begin(), output.end(), golden.begin())) {
        std::cout << "test pass!" << std::endl;
        return 0;
    } else {
        std::cout << "test fail!" << std::endl;
        return 1;
    }
    return 0;
}

int32_t main(int32_t argc, char* argv[])
{
    std::vector<float> input(1024);
    std::vector<float> golden(1024);
    for (uint32_t i = 0; i < 1024; i++){
        input[i] = 1;
        golden[i] = 1;
    }
    std::vector<float> output = optimize_vf_continious_align(input);
    return verify_result(output, golden);
}