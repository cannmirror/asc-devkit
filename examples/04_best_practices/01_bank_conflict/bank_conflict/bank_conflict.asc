/**
* Copyright (c) 2025 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/


/*!
 * \file bank_conflict.asc
 * \brief
 */
 
#include "data_utils.h"
#include "kernel_operator.h"
#include "acl/acl.h"
using KernelEntry = void(*)(uint32_t, void *, uint8_t *, uint8_t *, uint8_t *);

struct ArgInfo {
    std::string fileName;
    size_t length;
};

using AscendC::TPosition;
constexpr int32_t TOTAL_LENGTH = 4096;        // total length of data
constexpr int32_t BUFFER_NUM = 1;             // tensor num for each queue
constexpr int32_t BANKGROUP_SIZE = 1024 * 64; // one bank size is 4KB, with 16 banks
constexpr int32_t ONE_REPEAT_SIZE = 256;      // 256 bytes per repeat


class KernelAddV1 {
public:
    __aicore__ inline KernelAddV1() {}
    __aicore__ inline void Init(GM_ADDR x, GM_ADDR y, GM_ADDR z, AscendC::TPipe* pipeIn)
    {
        pipe = pipeIn;
        xGm.SetGlobalBuffer((__gm__ float *)x, TOTAL_LENGTH);
        yGm.SetGlobalBuffer((__gm__ float *)y, TOTAL_LENGTH);
        zGm.SetGlobalBuffer((__gm__ float *)z, TOTAL_LENGTH);
        pipe->InitBuffer(inQueueX, BUFFER_NUM, TOTAL_LENGTH * sizeof(float));
        pipe->InitBuffer(inQueueY, BUFFER_NUM, TOTAL_LENGTH * sizeof(float));
        pipe->InitBuffer(outQueueZ, BUFFER_NUM, TOTAL_LENGTH * sizeof(float));
    }
    __aicore__ inline void Process()
    {
        CopyIn();
        Compute();
        CopyOut();
    }

private:
    __aicore__ inline void CopyIn()
    {
        AscendC::LocalTensor<float> xLocal = inQueueX.AllocTensor<float>();
        AscendC::LocalTensor<float> yLocal = inQueueY.AllocTensor<float>();
        AscendC::DataCopy(xLocal, xGm, TOTAL_LENGTH);
        AscendC::DataCopy(yLocal, yGm, TOTAL_LENGTH);
        inQueueX.EnQue(xLocal);
        inQueueY.EnQue(yLocal);
    }
    __aicore__ inline void Compute()
    {
        AscendC::LocalTensor<float> xLocal = inQueueX.DeQue<float>();
        AscendC::LocalTensor<float> yLocal = inQueueY.DeQue<float>();
        AscendC::LocalTensor<float> zLocal = outQueueZ.AllocTensor<float>();
        AscendC::Add(zLocal, xLocal, yLocal, TOTAL_LENGTH);
        outQueueZ.EnQue<float>(zLocal);
        inQueueX.FreeTensor(xLocal);
        inQueueY.FreeTensor(yLocal);
    }
    __aicore__ inline void CopyOut()
    {
        AscendC::LocalTensor<float> zLocal = outQueueZ.DeQue<float>();
        AscendC::DataCopy(zGm, zLocal, TOTAL_LENGTH);
        outQueueZ.FreeTensor(zLocal);
    }

private:
    AscendC::TPipe* pipe;
    AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueX;
    AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueY;
    AscendC::TQue<AscendC::TPosition::VECOUT, BUFFER_NUM> outQueueZ;
    AscendC::GlobalTensor<float> xGm;
    AscendC::GlobalTensor<float> yGm;
    AscendC::GlobalTensor<float> zGm;
};

extern "C" __global__ __vector__ void add_custom_v1(GM_ADDR x, GM_ADDR y, GM_ADDR z)
{
    AscendC::TPipe pipe;
    KernelAddV1 op;
    op.Init(x, y, z, &pipe);
    op.Process();
}


void add_custom_do_v1(uint32_t numBlocks, void* stream, uint8_t* x, uint8_t* y, uint8_t* z)
{
    add_custom_v1<<<numBlocks, nullptr, stream>>>(x, y, z);
}


class KernelAddV2 {
public:
    __aicore__ inline KernelAddV2() {}
    __aicore__ inline void Init(GM_ADDR x, GM_ADDR y, GM_ADDR z, AscendC::TPipe* pipeIn)
    {
        pipe = pipeIn;
        xGm.SetGlobalBuffer((__gm__ float* )x, TOTAL_LENGTH);
        yGm.SetGlobalBuffer((__gm__ float* )y, TOTAL_LENGTH);
        zGm.SetGlobalBuffer((__gm__ float* )z, TOTAL_LENGTH);
        // xLocal size add 256 to avoid rr conflict
        pipe->InitBuffer(inQueueX, BUFFER_NUM, TOTAL_LENGTH * sizeof(float) + ONE_REPEAT_SIZE);
        // yLocal size adjust to 64KB - xLocal size to avoid rw conflict
        pipe->InitBuffer(inQueueY, BUFFER_NUM, BANKGROUP_SIZE - (TOTAL_LENGTH * sizeof(float) + ONE_REPEAT_SIZE));
        pipe->InitBuffer(outQueueZ, BUFFER_NUM, TOTAL_LENGTH * sizeof(float));
    }
    __aicore__ inline void Process()
    {
        CopyIn();
        Compute();
        CopyOut();
    }

private:
    __aicore__ inline void CopyIn()
    {
        AscendC::LocalTensor<float> xLocal = inQueueX.AllocTensor<float>();
        AscendC::LocalTensor<float> yLocal = inQueueY.AllocTensor<float>();
        AscendC::DataCopy(xLocal, xGm, TOTAL_LENGTH);
        AscendC::DataCopy(yLocal, yGm, TOTAL_LENGTH);
        inQueueX.EnQue(xLocal);
        inQueueY.EnQue(yLocal);
    }
    __aicore__ inline void Compute()
    {
        AscendC::LocalTensor<float> xLocal = inQueueX.DeQue<float>();
        AscendC::LocalTensor<float> yLocal = inQueueY.DeQue<float>();
        AscendC::LocalTensor<float> zLocal = outQueueZ.AllocTensor<float>();
        AscendC::Add(zLocal, xLocal, yLocal, TOTAL_LENGTH);
        outQueueZ.EnQue<float>(zLocal);
        inQueueX.FreeTensor(xLocal);
        inQueueY.FreeTensor(yLocal);
    }
    __aicore__ inline void CopyOut()
    {
        AscendC::LocalTensor<float> zLocal = outQueueZ.DeQue<float>();
        AscendC::DataCopy(zGm, zLocal, TOTAL_LENGTH);
        outQueueZ.FreeTensor(zLocal);
    }

private:
    AscendC::TPipe* pipe;
    AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueX;
    AscendC::TQue<AscendC::TPosition::VECIN, BUFFER_NUM> inQueueY;
    AscendC::TQue<AscendC::TPosition::VECOUT, BUFFER_NUM> outQueueZ;
    AscendC::GlobalTensor<float> xGm;
    AscendC::GlobalTensor<float> yGm;
    AscendC::GlobalTensor<float> zGm;
};

extern "C" __global__ __vector__ void add_custom_v2(GM_ADDR x, GM_ADDR y, GM_ADDR z)
{
    AscendC::TPipe pipe;
    KernelAddV2 op;
    op.Init(x, y, z, &pipe);
    op.Process();
}

void add_custom_do_v2(uint32_t numBlocks, void* stream, uint8_t* x, uint8_t* y, uint8_t* z)
{
    add_custom_v2<<<numBlocks, nullptr, stream>>>(x, y, z);
}


void KernelCall(KernelEntry kernelEntry, uint32_t numBlocks, void* stream, std::vector<ArgInfo> &inputsInfo,
                std::vector<ArgInfo> &outputsInfo)
{
    std::vector<uint8_t* > inputHost(inputsInfo.size());
    std::vector<uint8_t* > inputDevice(inputsInfo.size());
    std::vector<uint8_t* > outputHost(outputsInfo.size());
    std::vector<uint8_t* > outputDevice(outputsInfo.size());

    for (uint32_t i = 0; i < inputsInfo.size(); i++) {
        aclrtMallocHost((void **)(&inputHost[i]), inputsInfo[i].length);
        aclrtMalloc((void **)(&inputDevice[i]), inputsInfo[i].length, ACL_MEM_MALLOC_HUGE_FIRST);
        ReadFile(inputsInfo[i].fileName, inputsInfo[i].length, inputHost[i], inputsInfo[i].length);
        aclrtMemcpy(inputDevice[i], inputsInfo[i].length, inputHost[i], inputsInfo[i].length,
                              ACL_MEMCPY_HOST_TO_DEVICE);
    }

    for (uint32_t i = 0; i < outputsInfo.size(); i++) {
        aclrtMallocHost((void **)(&outputHost[i]), outputsInfo[i].length);
        aclrtMalloc((void **)(&outputDevice[i]), outputsInfo[i].length, ACL_MEM_MALLOC_HUGE_FIRST);
    }

    kernelEntry(numBlocks, stream, inputDevice[0], inputDevice[1], outputDevice[0]);
    aclrtSynchronizeStream(stream);
    for (uint32_t i = 0; i < outputsInfo.size(); i++) {
        aclrtMemcpy(outputHost[i], outputsInfo[i].length, outputDevice[i], outputsInfo[i].length,
                              ACL_MEMCPY_DEVICE_TO_HOST);
        WriteFile(outputsInfo[i].fileName, outputHost[i], outputsInfo[i].length);
        aclrtFree(outputDevice[i]);
        aclrtFreeHost(outputHost[i]);
    }

    for (uint32_t i = 0; i < inputsInfo.size(); i++) {
        aclrtFree(inputDevice[i]);
        aclrtFreeHost(inputHost[i]);
    }
}


int32_t main(int32_t argc, char* argv[])
{
    uint32_t numBlocks = 1;
    uint32_t dataLen = 4096;
    size_t inputByteSize = dataLen * sizeof(float);
    size_t outputByteSize = dataLen * sizeof(float);

    std::vector<ArgInfo> inputsInfo = {{"./input/input_x.bin", inputByteSize}, {"./input/input_y.bin", inputByteSize}};
    std::vector<ArgInfo> outputsV1Info = {{"./output/output_z_v1.bin", outputByteSize}};
    std::vector<ArgInfo> outputsV2Info = {{"./output/output_z_v2.bin", outputByteSize}};

    aclInit(nullptr);
    int32_t deviceId = 0;
    aclrtSetDevice(deviceId);
    aclrtStream stream = nullptr;
    aclrtCreateStream(&stream);

    KernelCall(add_custom_do_v1, numBlocks, stream, inputsInfo, outputsV1Info);
    KernelCall(add_custom_do_v2, numBlocks, stream, inputsInfo, outputsV2Info);

    aclrtDestroyStream(stream);
    aclrtResetDevice(deviceId);
    aclFinalize();

    return 0;
}
