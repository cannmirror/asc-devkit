/**
* Copyright (c) 2025 Huawei Technologies Co., Ltd.
* This program is free software, you can redistribute it and/or modify it under the terms and conditions of
* CANN Open Software License Agreement Version 2.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/


/* !
 * \file gather.asc
 * \brief
 */

#include <iostream>
#include <iterator>
#include <vector>
#include "acl/acl.h"
#include "tiling/platform/platform_ascendc.h"


template <typename type_data, typename type_idx>
__global__ void gather_custom(
    type_data* input,
    type_idx* index,
    type_data* gather_output,
    uint32_t in_width,
    uint32_t index_total_length)
{
    // Calculate global thread ID
    int32_t out_row = blockIdx.x * blockDim.x + threadIdx.x;

    // Maps to the row index of output tensor
    if (out_row >= index_total_length) {
        return;
    }

    // Single thread processes entire row (all columns) - enables coalesced memory access
    uint32_t in_row = index[out_row];
    for (int32_t col = 0; col < in_width; col++) {
        int input_idx = in_row * in_width + col;
        int output_idx = out_row * in_width + col;
        gather_output[output_idx] = input[input_idx];
    }
}

std::vector<float> gather(std::vector<float>& input, const uint32_t* in_shape, std::vector<uint32_t>& index)
{
    std::vector<float> output_stub;
    uint32_t input_total_length = input.size();
    size_t input_total_byte_size = input_total_length * sizeof(float);

    uint32_t index_total_length = index.size();
    size_t index_total_byte_size = index_total_length * sizeof(uint32_t);

    uint32_t output_total_length = index.size() * in_shape[1];
    size_t output_total_byte_size = output_total_length * sizeof(float);



    int32_t device_id = 0;
    aclrtStream stream = nullptr;

    uint8_t* input_host = reinterpret_cast<uint8_t *>(input.data());
    uint8_t* index_host = reinterpret_cast<uint8_t *>(index.data());
    uint8_t* output_host = nullptr;
    float* input_device = nullptr;
    uint32_t* index_device = nullptr;
    float* output_device = nullptr;
    // Init
    aclInit(nullptr);
    aclrtSetDevice(device_id);
    aclrtCreateStream(&stream);
    // Malloc memory in host and device
    aclrtMallocHost((void **)(&output_host), output_total_byte_size);
    aclrtMalloc((void **)&input_device, input_total_byte_size, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMalloc((void **)&index_device, index_total_byte_size, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMalloc((void **)&output_device, output_total_byte_size, ACL_MEM_MALLOC_HUGE_FIRST);
    aclrtMemcpy(input_device, input_total_byte_size, input_host, input_total_byte_size, ACL_MEMCPY_HOST_TO_DEVICE);
    aclrtMemcpy(index_device, index_total_byte_size, index_host, index_total_byte_size, ACL_MEMCPY_HOST_TO_DEVICE);
    // Calc splite params
    uint32_t numBlocks = 48;
    uint32_t thread_num_per_block = 256;
    uint32_t dyn_ubuf_size = 0;  // No need to alloc dynamic memory.
    // Call kernel funtion with <<<...>>>
    gather_custom<<<numBlocks, thread_num_per_block, dyn_ubuf_size, stream>>>(
              input_device, index_device, output_device, in_shape[1], index_total_length);
    aclrtSynchronizeStream(stream);
    // Copy result from device to host
    aclrtMemcpy(output_host, output_total_byte_size, output_device, output_total_byte_size, ACL_MEMCPY_DEVICE_TO_HOST);
    std::vector<float> output((float *)output_host, (float *)(output_host + output_total_byte_size));
    // Free memory
    aclrtFree(input_device);
    aclrtFree(index_device);
    aclrtFree(output_device);
    aclrtFreeHost(output_host);
    // DeInt
    aclrtDestroyStream(stream);
    aclrtResetDevice(device_id);
    aclFinalize();
    return output;
}

uint32_t verify_result(std::vector<float>& output, std::vector<float>& golden)
{
    auto print_tensor = [](std::vector<float>& tensor, const char* name) {
        constexpr size_t max_print_size = 20;
        std::cout << name << ": ";
        std::copy(tensor.begin(), tensor.begin() + std::min(tensor.size(), max_print_size),
            std::ostream_iterator<float>(std::cout, " "));
        if (tensor.size() > max_print_size) {
            std::cout << "...";
        }
        std::cout << std::endl;
    };
    print_tensor(output, "Output");
    print_tensor(golden, "Golden");
    if (std::equal(output.begin(), output.end(), golden.begin())) {
        std::cout << "[Success] Case accuracy is verification passed." << std::endl;
        return 0;
    } else {
        std::cout << "[Failed] Case accuracy is verification failed!" << std::endl;
        return 1;
    }
    return 0;
}

int32_t main(int32_t argc, char* argv[])
{
    constexpr uint32_t in_shape[2] = {100000, 128};
    constexpr uint32_t input_total_length = in_shape[0] * in_shape[1];
    std::vector<float> input(input_total_length);
    for (uint32_t i = 0; i < input_total_length; i++) {
        input[i] = i *1.2f;
    }

    constexpr uint32_t index_total_length = 12288;
    std::vector<uint32_t> index(index_total_length);
    for (uint32_t i = 0; i < index_total_length; i++) {
        if (i  % 2 == 0) {
            index[i] = i + 5;
        } else {
            index[i] = i + 3;
        }
    }

    std::vector<float> golden(index_total_length * in_shape[1]);
    for (uint32_t i = 0; i < index_total_length; i++) {
        for (uint32_t j = 0; j < in_shape[1]; j++) {
            golden[i * in_shape[1] + j] = input[index[i] * in_shape[1] + j];
        }
    }

    std::vector<float> output = gather(input, in_shape, index);
    if (output.empty()) {
        return 1;
    }
    return verify_result(output, golden);
}